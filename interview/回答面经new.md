# 面试相关

### 自我介绍

面试官您好，非常荣幸能够获得此次面试机会，我叫罗浩，本科毕业于浙江工业大学，硕士就读于华南理工大学，研究方向为无人艇自动驾驶。在本科和硕士阶段认真对待学习生活，先后获得国家励志奖学金、研究生一等奖学金等奖项。硕士阶段参与了国家重点专项开源无人智能网联系统应用示范项目，主要负责无人艇自动驾驶系统的开发工作，通过上述项目开发经历熟悉了 C++ 语言（设计模式）以及 Linux系统下常用命令及相关工具的使用，增加了项目开发沟通及协作能力；课余时间个人开发了基于线程池的轻量级并发服务器项目，过程中熟悉了并发编程和网络编程，进一步加深了对计算机网络、操作系统等基础知识的理解。个人认为自身具备岗位要求基本知识，具备较强的学习能力及团队合作能力，希望能够获得在贵司实习生岗位上继续提升自我的机会，这就是我的自我介绍，非常感谢面试官的聆听。

### 反问

工作中会使用到的技术有哪些？觉得我还欠缺什么？

### 有没有学过编程相关课程？

通过阅读一些计算机领域比较经典的书籍自学过C++、数据结构、操作系统、计算机网络等相关知识。

### 代码量有多少？

算上做项目、平时刷题和比赛相关代码大概有几万行。

# C++

## 三大特性，并举例（面向对象）

封装、继承、多态

- 封装：将客观事物进行抽象，将其属性和方法合成为一个类，同时又实现对属性和方法的权限控制，降低与外界的耦合度；

  举例：访问修饰符

- 继承：子类继承父类的各种属性和方法，同时还可以在父类的基础上重新定义和扩展父类的属性和方法，使其具有不同的功能，继承提高了代码的复用性及可维护性；

  举例：子类无需重新编写父类就对功能实现扩展

- 多态：向不同对象发同一消息，不同对象会产生不同的行为（即方法）。即一个接口，可以实现多种方法，提高代码复用性。

  举例：多态与非多态的实质区别就是函数地址是早绑定还是晚绑定

### 面向对象原则：高内聚、低耦合

内聚：每个模块尽可能独立完成自己的功能，不依赖于模块外部的代码；

耦合：模块和模块之间接口的复杂程度，模块之间联系越复杂耦合度越高。

### 多态实现

- 静态多态：函数重载、运算符重载、泛型编程。

  指编译期决定调用哪个函数。

- 动态多态：程序运行时根据基类的引用（指针）指向的对象来确定自己具体该调用哪一类的虚函数；子类重写父类虚函数

  运行期决定调用哪个函数。
  
  **重载实现原理**
  
  C++ 代码在编译时会根据函数名和参数列表类型对函数进行重命名。命名规则：
  
  ```cpp
  _Z + 函数名长度 + 函数名 + 类型首字母的小写 例：
  void f(int a, double b) 修改为 '_Z1fid'
  ```
  
  当发生函数调用时，编译器会根据传入的实参去逐个匹配，以选择对应的函数，如果匹配失败，编译器就会报错，这叫做**重载决议**。
  
  **动态多态实现原理**
  
  - 编译器会在类中生成一个虚函数表，虚函数表是一个存储类虚函数指针的数据结构， 虚函数表是由编译器自动生成与维护的；
  - virtual 成员函数会被编译器放入虚函数表中，存在虚函数时，每个对象中都有一个指向虚函数表的指针（vptr 指针）。

## 各类函数

### 虚函数

加了 virtual 修饰词的类的成员函数。

**作用**

实现了动态多态，用父类指针指向子类对象，通过父类指针调用子类的成员函数。

**虚函数指针**

- 虚函数指针内存布局位于所有成员变量之前，指向函数指针数组，即虚函数表；
- 对象在实例化的时候，虚函数指针就会创建，所以 是在**运行时**创建。

**虚函数表**

[C++中的虚函数表实现机制以及用C语言对其进行的模拟实现](https://blog.twofei.com/496/)

<img src="E:\Desktop\转码\面经回答\images\C++\虚函数指针.png" style="zoom: 67%;" />

- 基类内存按序排布，派生类内存放最后
- 派生类特有虚函数加至第一个虚函数表后
- 若派生类覆写基类虚函数，会覆盖对应虚函数表项

- 同一个类的不同实例共用同一份虚函数表
- 编译器在**编译阶段**就创建好，一个类只存在一份
-  C++中**虚函数表位于只读数据段（.rodata），也就是C++内存模型中的常量区；而虚函数则位于代码段（.text），也就是C++内存模型中的代码区。**

**实现原理**

编译器会给包含虚函数的对象添加一个虚函数指针，指向对应类的虚函数表，表内存储类中的虚函数地址。

如果派生类重写了基类中的虚函数，则派生类对象的虚函数表中保存的是派生类的虚函数地址，如果派生类没有重写基类中的虚函数，则派生类对象的虚函数表中保存的是父类的虚函数地址。

**使用虚函数成本**

- 对象内存因为存储虚函数指针而变大；
- 编译器需要维护虚函数表；
- 每次调用虚函数，需要到表中查找虚函数地址。

### 纯虚函数

一种特殊的虚函数，在基类中不能对虚函数给出有意义的实现，而把它声明为纯虚函数，它的实现留给基类的派生类去做。（包含纯虚函数的类成为抽象类）

```cpp
virtual int A() = 0;
```

### 虚函数和纯虚函数区别

- 格式不同；
- 虚函数是实现的；纯虚函数只是一个接口，一个声明，需留到子类去实现；
- 虚函数在子类中可以不重写；纯虚函数必须在子类中实现，才可以实例化子类。

### 内联函数

编译时，编译器将程序中出现的内联函数的调用表达式用内联函数的函数体进行了替换。具有以下特性

- 避免了函数调用的开销；
- 内联函数调用不需要寻址；
- 内联函数体要求代码简单，不能包含复杂的结构控制语句，如果内联函数函数体过于复杂，编译器将自动把内联函数当成普通函数来执行；
- 会增加目标程序代码量，增加空间开销。

### 析构函数

对象结束生命周期时系统自动调用，释放对象使用的资源，并销毁对象的非 static 数据成员。

### 虚函数可以是内联函数吗

可以，但当虚函数表现多态性的时候不能内联。

虚函数唯一可以内联的时候：编译器知道所调用的对象是哪个类，这只有在编译器具有实际对象而不是对象的指针或者引用时才会发生。

### 为什么将析构函数设置成虚函数

防止内存泄漏，当父类指针指向子类对象的时候，释放父类指针，如果此时析构函数不是虚函数，那么将只会调用父类的析构函数，不会调用子类的析构函数，造成内存泄漏问题。

### 构造函数可以为虚函数吗？

不能，如果构造函数是虚函数，那么调用构造函数就需要去找虚表指针 vptr，而此时虚表指针 vptr 还没有初始化。

### 构造函数和析构函数中能否调用虚函数？

不能。

- 语法上说，调用完全没有问题；
- 但是从效果上看，往往不能达到需要的目的。

Effective 的解释是：
派生类对象构造期间进入基类的构造函数时，对象类型变成了基类类型，而不是派生类类型。
同样，进入基类析构函数时，对象也是基类类型。

> 在基类的构造过程中，虚函数调用从不会被传递到派生类中，代之的是，派生类对象表现出来的行为好像其本身就是基类。

### 什么情况调用拷贝构造，什么情况调用赋值操作

拷贝构造：

- 用一个对象初始化另一个对象；
- 对象以值传递的方式传递给函数参数；
- 函数局部对象以值传递的方式从函数返回。

赋值操作：

将一个对象赋值给另外一个对象。

### C++空类包含哪些函数

编译器会生成 6 个成员函数：

- 缺省构造函数。
- 缺省拷贝构造函数。
- 缺省析构函数。
- 缺省赋值运算符。
- 缺省取址运算符。
- 缺省取址运算符 const。

```cpp
class Empty
{};

class Empty
{
  public:
    Empty();                            //缺省构造函数
    Empty(const Empty &rhs);            //拷贝构造函数
    ~Empty();                           //析构函数 
    Empty& operator=(const Empty &rhs); //赋值运算符
    Empty* operator&();                 //取址运算符
    const Empty* operator&() const;     //取址运算符(const版本)
};
```

### 虚函数能否私有化？

可以。

### C++中成员函数能够同时用static和const进行修饰？

No 

  static修饰的函数表示该函数是属于类的，而不是属于某一个对象的，没有this指针。 

  const修饰的函数表示该函数不能改变 this 中的内容，会有一个隐含的const this指针。 

  两者是冲突矛盾的。

## C++11特性

[c++11新特性](https://cloud.tencent.com/developer/article/1745592)

### 自动类型推导

- auto：让编译器在编译期就推导出变量的类型，可以通过=右边的类型推导出变量的类型；
- decltype：decltype 用于推导表达式类型，这里只用于编译器分析表达式的类型，表达式实际不会进行运算。

### 左值右值

### 初始化列表

- 类成员中存在常量，如 const int a, 只能用初始化不能赋值；

- 类成员中存在引用，同样只能使用初始化不能赋值；

- 没有默认构造函数的类类型必须使用初始化列表；

  > 因为使用初始化列表可以不必调用默认构造函数来初始化，而是直接调用拷贝构造函数初始化。

- 提高效率。

### 智能指针

## C++14、C++17、C++20 都有什么新特性

## 区别

### C 与 C++ 区别（函数/类/struct/class）

- C 面向过程，C++ 面向对象；
- C++ 有新增的语法和关键字；
  - 语法：头文件；命名空间；
  - 关键字：malloc 和 free / new 和 delete
- C++ 中有重载和虚函数，以实现多态；
- struct 中 C++ 中不仅可以有成员变量还可以有成员函数；
- C++ 支持内联函数；
- C++ 中增加了模板，提供了 STL 标准库。

### new / delete malloc / free 区别

- new/delete 是操作符，malloc/free 是库函数。
- new / delete 后跟类型，malloc 后跟字节长度。
- 对于非内部数据类型，malloc / free 无法满足动态对象的要求。

new 执行过程：1. 分配内存空间（malloc）；2. 调用对象构造函数；3. 返回空间首地址。

delete 执行过程： 1. 调用对象析构函数；2. 回收内存空间（free）。

#### delete 多次会发生什么？

只有第一次 delete 被正确执行，之后的 delete 发生异常。

> delete 运算会释放指针所指的地址空间，不会判断空间是否被占用，delete 结束后不会将指针赋值为空。

解决：delete 运算后将指针赋值为空。

### 指针和引用的区别

- 定义和性质不同。指针是一种数据类型，用于保存地址类型的数据，而引用可以看成是变量的别名；
- 引用不可以为空，当被创建的时候必须初始化，而指针变量可以是空值，在任何时候初始化；
- 指针的值在初始化后可以改变，即指向其它的存储单元，而引用在进行初始化后就不会再改变了；
- sizeof 引用得到的是所指向的对象的大小，而 sizeof 指针得到的是指针变量本身的大小；
-  指针作为函数参数传递时传递的是指针变量的值，而引用作为函数参数传递时传递的是实参本身，而不是拷贝副本；
- 指针和引用进行++运算意义不一样。

### C++ 中 struct 和 class 区别

- struct 更适合看成是一个数据结构的实现体，class 更适合看成是一个对象的实现体；
- 最本质的区别是默认的访问控制：
  - 默认的继承访问权限：struct 是 public 的，class 是 private 的；
  - 默认的成员访问权限：struct 是 public 的，class 是 private 的。

### strlen 和 sizeof 的区别

- sizeof 是运算符，strlen 是库函数；
- sizeof 在编译时计算，strlen 在运行时计算；
- sizeof 返回对象使用的最大字节数，strlen 返回字符串长度；
- sizeof 参数类型多样，strlen 必须是字符串指针。

### memcpy 和 memmove 的区别

```cpp
//从存储区 str2 复制 n 个字节到存储区 str1
void* memcpy(void* str1, const void* str2, size_t n)
void* memmove(void* str1, const void* str2, size_t n)
```

memmove() 能够保证源串在被覆盖之前将重叠区域的字节拷贝到目标区域中，复制后源区域的内容会被更改。

**代码实现**

```cpp
void* memcpy(void* dest, const void* src, size_t n) {
    assert(src != nullptr && dest != nullptr);
    char* tmp_dest = (char*) dest;
    const char* tmp_src = (const char*) src;
    while(count) {
        *tmp_dest++ = *tmp_src++;
        count--;
    }
    return dest;
}
```

```cpp
void* memmove(void* dest, const void* src, size_t count) {
    assert(src != nullptr && dest != nullptr);
    char* tmp_dest = (char*) dest;
    const char* tmp_src = (const char*)src;
    if(tmp_src < tmp_dest) {
        while(count) {
            *tmp_dest++ = *tmp_src++;
            count--;
        }
    }else if(tmp_src > tmp_dest) { //当src地址大于dest地址时，从后进行拷贝
        tmp_src += count - 1;
        tmp_src += count - 1;
        while(count) {
            *tmp_dest-- = *tmp_src--;
            count--;
        }
    }
    return dest;
}
```

### malloc、vmalloc 和 kmalloc 区别

- kmalloc 和 vmalloc 是分配的是内核的内存；malloc 分配的是用户的内存；
- kmalloc 保证分配的内存在物理上是连续的；malloc 和 vmalloc 保证的是在虚拟地址空间上的连续；
- vmalloc 比 kmalloc 要慢，因为 vmalloc 函数为了把物理内存上不连续的页转换为虚拟地址空间上连续的页，必须专门建立页表项。

### malloc 和 realloc 的区别

```cpp
void realloc(void *ptr, size_t new_size);
```

原理：

- 内存可扩大或则缩小

  - 若扩大，将原来内存块保留，在后面新增一块内存块；
  - 若缩小，则将内存块的后半部分直接拿掉。

- 内存块无法扩大缩小

  重新开辟一个新的内存空间，并把原来内存空间的内容拷贝到新的内存空间里。

### overload、override、overwrite 的分别

**1. Overload（重载）**

重载的概念最好理解，在同一个类声明范围中，定义了多个名称完全相同、参数（类型或者个数）不相同的函数，就称之为Overload（重载）。重载的特征如下：

- 相同的范围（在同一个类中）；
- 函数名字相同；
- 参数不同；
- virtual 关键字可有可无。

**2. Override（覆盖）**

覆盖的概念其实是用来实现C++多态性的，即子类重新改写父类声明为virtual的函数。Override（覆盖）的特征如下：

- 不同的范围（分别位于派生类与基类）；
- 函数名字相同；
- 参数列表完全相同；
- 基类函数必须有virtual 关键字。

**3. Overwrite（改写）**

改写是指派生类的函数屏蔽（或者称之为“隐藏”）了与其同名的基类函数。正是这个C++的隐藏规则使得问题的复杂性陡然增加，这里面分为两种情况讨论：

- 如果派生类的函数与基类的函数同名，但是参数不同。那么此时，不论有无virtual关键字，基类的函数将被隐藏（注意别与重载混淆）。
- 如果派生类的函数与基类的函数同名，并且参数也相同，但是基类函数没有virtual关键字。那么此时，基类的函数被隐藏（注意别与覆盖混淆）。

## 关键字和操作符

### const

- 修饰普通变量：表示常量，不可修改；

- 修饰指针变量

  - 修饰指针指向内容，则内容为不可变量（常量指针）

    ```cpp
    const int* p = 8;
    ```

  - 修饰指针，则指针为不可变量（指针常量）

    ```cpp
    int* const p = &a
    ```

- const 修饰形参

  ```cpp
  // 值传递，不需 const 修饰，函数会自动产生临时变量复制实参值
  void fuc(const int a)
  //const 修饰指针形参，可以防止指针被篡改
  void fuc(int* const a)
  //自定义类型的参数传递，需要临时对象复制参数，对于临时对象的构造，需要调用构造函数，比较浪费时间，因此我们采取 const 外加引用传递的方法。
  void fuc(const foo& a)
  ```

- const 修饰成员函数

  目的是防止成员函数修改被调用对象的值，如果我们不想修改一个调用对象的值，所有的成员函数都应当声明为 const 成员函数。尽量按照要求将所有的不需要改变对象内容的函数都作为 const 成员函数。

  ```cpp
  int fuc() const {}
  ```

#### 如何修改 const 变量

- 若 const 变量为局部变量；

  可以通过指针修改。

  ```cpp
      const int age = 39;
  
      //1.直接赋值，导致编译错误
      //age = 40;
  
      //2.使用指针修改
      int * p = (int *)&age;
      *p = 40;
  
      cout << "age=" << age << endl;
      cout << "*p=" << *p << endl;
      cout << "&age=" << &age << endl;
      cout << "p=" << (void*)p << endl;
  ```

  - 若 const 变量不为 volatile

    常量被修改吗，但 age 值和 *p 的值并不相同，age 值为 39，而 *p 的值是 40，且 p 确实指向了 age 所在的地址空间。age 是 const 变量，编译器对 age 在预处理的时候就进行了替换。因为 age 进行了常量折叠，编译器只对 const 变量的值读取一次。所以打印的是 39。age 实际存储的值被指针p所改变。但是为什么能改变呢，从其存储地址可以看出来，其存储在堆栈中。

    > 常量折叠：const变量（即常量）值放在编译器的符号表中，计算时编译器直接从表中取值，省去了访问内存的时间，这是编译器进行的优化。

  - 若 const 变量为 volatile，即

    ```
    const volatile int age = 39;
    ```

    则不会发生常量折叠的问题。

- 若 const 变量为全局变量

  不能修改。因为 const 存储的空间不可写，没有写权限。

### volatile

volatile 限定符是用来告诉计算机，所修饰的变量的值随时都会进行修改。用于防止编译器对该代码进行优化。通俗的讲就是编译器在用到这个变量时必须每次都从内存中重新读取这个变量的值，而不是使用保存在寄存器里的备份。

**可以和 const 同时使用吗？**

volatile 的含义是防止编译器对该代码进行优化，这个值可能变掉的。而 const 的含义是在代码中不能对该变量进行修改。因此，它们本来就不是矛盾的。

**指针可以是 volatile**。

### static

static 是一个关键字，可以用来修饰局部变量、全局变量、函数、成员变量和成员方法。

**作用**

- 限制数据的作用域；

  所有没有加 static 的全局变量和函数都具有全局可见性，其它源文件中也可以访问。被 static 修饰的全局变量和函数只能在当前源文件中访问，其它源文件访问不了，利用这个特性可以在不同的文件中定义同名变量和同名函数，而不必担心命名冲突。

- 延长数据的生命周期；

   普通的局部变量出了作用域就会释放，而静态变量存储在静态区，知道程序运行结束才会释放。

- 静态成员被该类所有对象共享。

  static 关键字可以修饰类中的成员变量和成员方法，被称为静态成员变量和静态成员方法，静态成员拥有一块单独的存储区，不管创建多少个该类的对象，所有对象都共享这一块内存。

**特性**

- 静态变量默认初始化值为0，如果没有显式初始化静态变量或者初始化为0的静态变量会存储在 BSS 段，而初显式初始化的静态变量存储在数据段；
- 静态成员函数中不能访问普通的成员变量，只能访问静态成员变量，并且在静态成员函数中没有 this 指针。

### extern

- 置于变量声明或者函数声明前，表示变量或者函数的定义在别的文件中；
- 表示声明的变量为全局变量，该变量未初始化或者初始化为 0 则保持在程序的 BSS 段；如果初始化不为 0 则保存在程序的 DATA 段；
- extern “C” ：指示编译器这部分代码按照 C 语言的标准编译 （主要针对重载）。

### explicit

放于构造函数前防止类构造函数的隐式自动转换。

### auto 和 decltype

auto 实现自动类型推断，要求进行显示初始化；

decltype 将变量的类型声明为表达式指定的类型。

```cpp
auto varname = value;
decltype(exp) varname [= value];
```

#### auto 不允许使用的四个场景

- 不能作为函数形参使用；

  ```cpp
  int func(auto a, auto b)
  ```

- 不能用于类的非静态成员变量的初始化；

  ```cpp
  class Test
  {
  	auto a = 0;//error
  	static auto b = 2;//error,类的静态非常量成员不允许在类内部直接初始化
  	static const auto c = 10;//ok
  };
  ```

- 不能用于定义数组；

  ```cpp
  int func()
  {
  	int array[] = { 1,2,3,4,5 };//ok
  	auto t1 = array;//ok，t1 -> int *
  	auto t2[] = array;//error，auto无法定义数组
  	auto t3[] = { 1,2,3,4,5 };//error，auto无法定义数组
  }
  ```

- 不能用于推导模板参数。

### const 和 define 的区别

const 在 C 语言中表示只读，编译器禁止对它修饰的变量进行修改，在 C++ 中增加了常量的语义;

 define 用于定义宏，而宏也可以用于定义常量。

**区别**

- const 生效于编译阶段，而 define 生效于预处理阶段；
- define只是简单的字符串替换，没有类型检查，而 const 有对应的数据类型；
- 用 define 定义的常量是不可以用指针变量去指向的，用 const 定义的常量是可以用指针去指向该常量的地址的；
- define 不分配内存，给出的是立即数，有多少次使用就进行多少次替换，在内存中会有多个拷贝，消耗内存大，const 在静态存储区中分配空间，在程序运行过程中内存中只有一个拷贝；
- 可以对 const 常量进行调试，但是不能对宏常量进行调试。

### sizeof

返回数据类型的字节数

- bool 1 char 1 short 2 int 4 long4 longlong8 float4 double8
- 指针：64位是8，32位是4。

**原理**

**在编译的时候，查找符号表**，判断类型，然后根据基础类型来取值。如果 sizeof 运算符的参数是一个**不定长数组，则该需要在运行时计算数组长度**。

### #pragma pack(n)

设定结构体、联合以及类成员变量以 n 字节方式对齐

#pragma pack(n) 使用

```cpp
#pragma pack(push)  // 保存对齐状态
#pragma pack(4)     // 设定为 4 字节对齐

struct test
{
    char m1;
    double m4;
    int m3;
};

#pragma pack(pop)   // 恢复对齐状态
```

### 内存对齐

**概念**

计算机系统对基本类型数据在内存中存放的位置有限制，它们会要求这些数据的首地址的值是某个数 k（通常它为4或8）的倍数。

**原因**

- 不是所有硬件平台都能访问任意地址；
- 访问未对齐的内存，处理器可能需要作两次内存访问；而对齐的内存访问仅需要一次。

**规则**

- 数据类型自身对齐值：基本数据类型的自身所占空间大小；
- 指定对齐值：使用#pragam pack(value)时，指定的对齐值value；
- 结构体或类的自身对齐值：其中成员对齐值最大的那个值；
- 结构体和类的有效对齐值：自身对齐值和指定对齐值中较小的那个值；
- 结构体第一个成员的偏移量（offset）为0，以后每个成员相对于结构体首地址的 offset 都是该成员大小与有效对齐值中较小那个的整数倍，如有需要编译器会在成员之间加上填充字节；
- 结构体的总大小为有效对齐值的整数倍，如有需要编译器会在最末一个成员之后加上填充字节。

### = delete

C++11增加了=delete修饰符，明确表达虽然声明了某函数，但是又禁止它们被使用的意思。

```cpp
Singleton(const Singleton& st) = delete;
Singleton& operator=(const Singleton& st) = delete;
```

## 指针

### 野指针

#### 概念

 野指针是指指向的位置是随机的、不可知的、不正确的。

#### 产生原因

- 指针变量未初始化；

  指针变量没有初始化，其值是随机的，也就是指针变量指向的是不确定的内存，如果对它解除引用，结果是不可知的。

- 指针释放后未悬空；

  有时候指针在释放后没有复制为 nullptr，虽然指针变量指向的内存被释放掉了，但是指针变量中的值还在，这时指针变量就是指向一个未知的内存，如果对它解除引用，结果是不可知的。

- 指针操作超出了变量的作用域

  函数中返回了局部变量的地址或者引用，因为局部变量出了作用域就释放了，这时候返回的地址指向的内存也是未知的。

#### 避免

- 指针变量一定要初始化；
- 释放后置为 nullptr。

### 二级指针

C 语言在进行函数调用的时候，是将实参的值复制一份，并将其副本传递到函数调用里，如果形参定义的不是指针，那么在函数内部改变数值，不会对实参本来的值发生改变。而将形参定义成指针的话，那么传到函数里面的值虽然是实参地址的一个副本，但是地址里存的值发生了改变，也就导致实参本来的值也发生了改变。

因此如果要在函数内改变一个指针的值，就需要将形参定义为二级指针。

## 智能指针

**概念**

智能指针是存储指向动态分配对象指针的类，用于生存期控制，能确保在离开指针所在作用域时，自动地销毁动态分配的对象，以防止内存泄漏。

### 实现原理

智能指针是一个对象。它的实现原理是基于 C++ 的 RAII 机制，主要利用的是 C++ 中的对象生命周期结束时会自动调用析构函数的特性。将指针封装在一个类里，在析构函数中封装释放指针的操作，从而通过自动调用析构函数来自动释放指针，以达到内存管理，防止内存泄漏的目的。

### auto_ptr

特点：C++ 98 设计，采用所有权模式，C++ 11 弃用，存在潜在内存崩溃问题。（复制、赋值操作不会报错，但会剥夺原来指针所有权，若再次访问原来指针会出现内存崩溃）

### unique_ptr

特点：实现独占式拥有，保证同一时间内只有一个智能指针可以指向该对象。不支持复制和赋值操作，支持转移语义实现所有权转移。

作用：用于取代 auto_ptr。

### shared_ptr

特点：实现共享式拥有，多个智能指针可以指向相同对象，对象和其有关资源会在“最后一个引用被销毁”时释放。采用计数机制来表明资源被几个指针共享。

作用：支持定制型删除器（custom deleter），可防范 Cross-DLL 问题（对象在动态链接库（DLL）中被 new 创建，却在另一个 DLL 内被 delete 销毁）、自动解除互斥锁。

内部原理：

包含两个指针一个指向资源，一个指向资源引用计数类，类中记录了引用资源的shared_ptr 个数和 weak_ptr 个数。

[shared_ptr的内部实现原理](https://blog.csdn.net/liyazhen2011/article/details/103636202)

**按引用传参不增加引用计数**

### weak_ptr

特点：weak_ptr 不控制对象生命周期，指向一个 shared_ptr 管理的对象，它的构造和析构不会引起引用计数的增加或减少。

作用：可打破循环引用（cycles of references，两个其实已经没有被使用的对象彼此互指，使之看似还在 “被使用” 的状态）的问题。

### shared_ptr

> https://cloud.tencent.com/developer/article/1688444

多个智能指针可以共享同一个对象，对象的最末一个拥有着有责任销毁对象，并清理与该对象相关的所有资源。

* 支持定制型删除器（custom deleter），可防范 Cross-DLL 问题（对象在动态链接库（DLL）中被 new 创建，却在另一个 DLL 内被 delete 销毁）、自动解除互斥锁

#### 实现原理

内部包含一个指向引用计数的指针、一个指向共享资源的指针和一个锁。

shared_ptr的原理：是**通过引用计数的方式来实现多个shared_ptr对象之间共享资源**。

1. shared_ptr在其内部，**给每个资源都维护了着一份计数，用来记录该份资源被几个对象共享**。
2. 在对象被销毁时(也就是**析构函数调用**)，就说明自己不使用该资源了，**对象的引用计数减一**。
3. **如果引用计数是0**，就说明自己是最后一个使用该资源的对象，**必须释放该资源**；
4. 如果不是0，就说明除了自己还有其他对象在使用该份资源，不能释放该资源，否则其他对象就成野指针了。

#### 是否线程安全

多个线程同时修改引用计数，线程不安全，需要加锁。

### auto_ptr 与 unique_ptr 比较

* auto_ptr 可以赋值拷贝，复制拷贝后所有权转移；unqiue_ptr 无拷贝赋值语义，但实现了`move` 语义；
* auto_ptr 对象不能管理数组（析构调用 `delete`），unique_ptr 可以管理数组（析构调用 `delete[]` ）；

### shared_ptr 和 unique_ptr 能否互转

- 由于 unique_ptr 的语义是唯一拥有 ownership，那只要对他执行move操作就能把 ownership 转移出去给shared_ptr；
- 由于 shared_ptr 本质上是多人拥有 ownership，所以要转换成语义更加严格的单人拥有 ownership 是做不到的。

### 使用场景

- 多个指针指向一个对象的情况，使用 shared_ptr；
- 单个指针指向一个对象的情况，使用 unique_ptr；
- 出现循环引用问题，使用 weak_ptr 来辅助 shared_ptr。

### 线程安全

- 同一个 shared_ptr 被多线程读，线程安全；
- 同一个 shared_ptr 被多线程写，不是线程安全；
- 共享引用计数的不同的 shared_ptr 被多线程写，是线程安全。

### 内存泄漏

当两个类对象中各自有一个 shared_ptr 指向对方时，会造成循环引用，使引用计数失效，从而导致内存泄漏。

**解决办法**

使用 weak_ptr 来打破循环引用，weak_ptr 的构造函数不会修改引用计数的值，从而不会对对象的内存进行管理，一旦最后一个指向对象的 shared_ptr 被销毁，对象就会被释放。

### 智能指针和指针的区别

- 智能指针会自动释放所指的对象（智能指针采用 RAII 机制，对普通指针加了一层封装机制）；指针需要程序员手动释放
- 指针是一种数据类型；智能指针是类模板。
- 对普通指针加了一层封装机制

### 手写智能指针

[CPlusPlusThings/learn_class/modern_C++_30/smart_ptr at master · Light-City/CPlusPlusThings (github.com)](https://github.com/Light-City/CPlusPlusThings/tree/master/learn_class/modern_C++_30/smart_ptr)

## 模板

### 类模板和函数模板的区别

- 类模板不支持模板参数自动推导；
- 类模板在模板参数列表可以有默认参数。

#### 模板特例化

模板特例化：模板的一个或多个模板参数被指定为特定的类型。

## RAII 机制

Resource Acquisition Is Initialization，资源获取即初始化，是 C++ 用于管理资源、避免泄漏的方法。

**原理**

充分的利用了 C++ 语言局部对象自动销毁的特性来控制资源的生命周期。

**步骤**

- 设计一个类封装资源；
- 在构造函数中初始化；
- 在析构函数中执行销毁操作；
- 使用时声明一个该类的对象。

## 宏定义

**概念**使用“标识符”来表示“替换列表”中的内容。标识符称为宏名，在预处理过程中，预处理器会把源程序中所有宏名，替换成宏定义中替换列表中的内容。

**不进行类型检查**，只是简单的字符串替换，不进行类型的检查，在预处理阶段。

## typedef 和 define 的区别

- typedef 用来定义一种数据类型的别名；define 用来定义常量和宏；
- typedef 在编译阶段，有类型检查；define 在预处理阶段，不进行类型检查；
- typedef有作用域限定，define不受作用域约束，只要是在define声明后的引用都是正确的；
- typedef 是语句，需加分号；define 不是语句，不用加分号。

## 浅拷贝和深拷贝

根本区别：在于是否真正获取一个对象的复制实体，而不是“ 引用 ”。

- 浅拷贝又称值拷贝，将源对象的值拷贝到目标对象中，如果对象中有某个成员是指针类型数据，并且是在堆区创建，则使用浅拷贝仅仅拷贝的是这个指针变量的值，也就是在目标对象中该指针类型数据和源对象中的该成员指向的是同一块堆空间。这样会带来一个问题，就是在析构函数中释放该堆区数据，会被释放多次。默认的拷贝构造函数和赋值运算符重载都是浅拷贝。
- 深拷贝，深拷贝在拷贝的时候先开辟出和源对象大小一样的空间，然后将源对象里的内容拷贝到目标对象中去，这样指针成员就指向了不同的内存位置。并且里面的内容是一样的，这样不但达到了拷贝的目的，还不会出现问题，两个对象先后去调用析构函数，分别释放自己指针成员所指向的内存。即为每次增加一个指针，便申请一块新的内存，并让这个指针指向新的内存，深拷贝情况下，不会出现重复释放同一块内存的错误。

简化：

浅拷贝就是增加了一个指向相同堆区的指针，这将导致在析构的时候会重复释放。默认的拷贝构造和运算符重载都是浅拷贝。深拷贝是在拷贝的时候将内容申请内存，重新拷贝一份，放到内存中，指针指向这个新拷贝的部分，这样就不会出现析构的时候重复释放的问题了。

## 左值引用和右值引用

- 可以取地址的，有名字的，非临时的就是左值；

- 不能取地址的，没有名字的，临时的就是右值。包括字面常量、表达式以及返回值的函数

- 左值引用就是对一个左值进行引用；

- 右值引用就是对一个右值进行引用。

  C++ 11 新增了右值引用，使用 && 声明。

  使用场景：右值引用可以实现移动语义和完美转发。主要目的：

  - 消除两个对象交互时不必要的对象拷贝，节省运算存储资源，提高效率；
  - 能够更简洁明确地定义泛型函数。

### 移动语义和完美转发

[移动语义（move semantic）和完美转发（perfect forward）](https://blog.csdn.net/summerhust/article/details/110677472)

`std::move()`：将左值转换为右值；

`std::forward<>()`：保留参数的左右值类型，实现完美转发。

## 简述一下 C++ 的重载和重写

### 重载

- 重载是指不同的函数使用相同的函数名，但是函数的参数列表不同。调用的时候根据函数的参数来区别不同的函数，返回类型可以不一致；
- 重载的规则
  - 函数名相同；
  - 必须具有不同的参数列表；
  - **可以有不同的访问修饰符。**
- 重载用来实现静态多态；
- 重载是多个函数或者同一个类中方法之间的关系，是**平行关系**。

### 重写

- 重写是指在派生类中重新对基类中的虚函数重新实现。即函数名和参数都一样，只是函数的实现体不一样，返回类型需一致；
- 重写的规则
  - 方法声明必须完全与父类中被重写的方法相同；
  - **访问修饰符的权限要大于或者等于父类中被重写的方法的访问修饰符**；
  - 子类重写的方法可以加 virtual，也可以不加。
- 重写用来实现动态多态；
- 重写是父类和子类之间的关系，是垂直关系。

### 隐藏

隐藏的实质是，在函数查找时，名字查找先于类型检查。当派生类的对象指针，引用指向基类和派生类相同函数名的函数时，调用的是派生类的函数。

## Lambda 表达式

### 用法

lambda 表达式定义了一个匿名函数，并且可以捕获一定范围内的变量。

```cpp
[ capture ] ( params ) opt -> ret { body; };
```

其中 capture 是捕获列表，params 是参数表，opt 是函数选项，ret 是返回值类型，body是函数体。

初始化列表不能用于返回值的自动推导：

```cpp
auto x1 = [](int i){ return i; };  // OK: return type is int
auto x2 = [](){ return { 1, 2 }; };  // error: 无法推导出返回值类型
```

#### 捕获列表

- [] 不捕获任何变量。
- [&] 捕获外部作用域中所有变量，并作为引用在函数体中使用（按引用捕获）。
- [=] 捕获外部作用域中所有变量，并作为副本在函数体中使用（按值捕获）。
- [=，&foo] 按值捕获外部作用域中所有变量，并按引用捕获 foo 变量。
- [bar] 按值捕获 bar 变量，同时不捕获其他变量。
- [this] 捕获当前类中的 this 指针，让 lambda 表达式拥有和当前类成员函数同样的访问权限。如果已经使用了 & 或者 =，就默认添加此选项。捕获 this 的目的是可以在 lamda 中使用当前类的成员函数和成员变量。

#### 函数选项

默认情况下，对于一个值被拷贝的变量，lambda 不会改变其值。如果我们希望能改变一个被捕获的变量的值，就必须在参数列表首加上关键字 mutable。

### 原理

1. 创建 **lambda匿名类**，使用 lambda 表达式的函数体重载 **operator()**（所以 lambda 表达式 也叫匿名函数对象）；
2. 创建 lambda 对象；
3. 通过对象调用 **operator()**。

## 强制类型转换运算符

#### static_cast

* 用于非多态类型的转换
* 不执行运行时类型检查（转换安全性不如 dynamic_cast）
* 通常用于转换数值数据类型（如 float -> int）
* 可以在整个类层次结构中移动指针，子类转化为父类安全（向上转换），父类转化为子类不安全（因为子类可能有不在父类的字段或方法）

> 向上转换是一种隐式转换。

#### dynamic_cast

```cpp
dynamic_cast<type*> (e);
dynamic_cast<type&> (e);
dynamic_cast<type&&> (e);
```

* 用于多态类型的转换
* 执行行运行时类型检查
* 只适用于指针或引用
* 对不明确的指针的转换将失败（返回 nullptr），但不引发异常
* 可以在整个类层次结构中移动指针，包括向上转换、向下转换

#### const_cast 

* 用于删除 const、volatile 和 __unaligned 特性（如将 const int 类型转换为 int 类型 ）

#### reinterpret_cast

* 用于位的简单重新解释
* 滥用 reinterpret_cast 运算符可能很容易带来风险。 除非所需转换本身是低级别的，否则应使用其他强制转换运算符之一。
* 允许将任何指针转换为任何其他指针类型（如 `char*` 到 `int*` 或 `One_class*` 到 `Unrelated_class*` 之类的转换，但其本身并不安全）
* 也允许将任何整数类型转换为任何指针类型以及反向转换。
* reinterpret_cast 运算符不能丢掉 const、volatile 或 __unaligned 特性。 
* reinterpret_cast 的一个实际用途是在哈希函数中，即，通过让两个不同的值几乎不以相同的索引结尾的方式将值映射到索引。

## 可变参数模板新特性

在 C++11 之前，类模板和函数模板只能含有**固定数量的模板参数**。C++11 增强了模板功能，它对参数进行了高度泛化，**允许模板定义中包含 0 到任意个、任意类型的模板参数**，这就是可变参数模板。

# STL

## 容器类型

- 序列式容器：容器并非排序的，元素的插入位置与元素的值无关，包含 vector、deque、list；
- 关联式容器：元素是排序的，包含 set、multiset、map、multimap；
- 容器适配器：封装了一些基本的容器，使之具备了新的函数功能，包含 stack、queue、priority_queue。

## 容器时间复杂度

- 内存连续存放的 插入: O(N) 查看: O(1) 删除: O(N) 比如：vector；
- 内存链表存放的 插入: O(1) 查看: O(N) 删除: O(1) 比如：list；
- 内存红黑树存放的 插入: O(logN) 查看: O(logN) 删除: O(logN) 比如：map、set、multimap、multiset；
- 内存哈希表存放的 插入: O(1)，最坏情况O(N) 查看: O(1)，最坏情况O(N) 删除: O(1)，最坏情况O(N) ；unordered_map、unordered_set、unordered_multimap、 unordered_multiset。

## STL 容器及其底层实现

| 容器                                                         | 底层数据结构      | 时间复杂度                                                 | 有无序 | 可不可重复 | 其他                                                         |
| :----------------------------------------------------------- | ----------------- | ---------------------------------------------------------- | ------ | ---------- | ------------------------------------------------------------ |
| [array](https://github.com/huihut/interview/tree/master/STL#array) | 数组              | 随机读改 O(1)                                              | 无序   | 可重复     | 支持随机访问                                                 |
| [vector](https://github.com/huihut/interview/tree/master/STL#vector) | 数组              | 随机读改、尾部插入、尾部删除 O(1)、头部插入、头部删除 O(n) | 无序   | 可重复     | 支持随机访问                                                 |
| [deque](https://github.com/huihut/interview/tree/master/STL#deque) | 双端队列          | 头尾插入、头尾删除 O(1)                                    | 无序   | 可重复     | 一个中央控制器 + 多个缓冲区，支持首尾快速增删，支持随机访问  |
| [forward_list](https://github.com/huihut/interview/tree/master/STL#forward_list) | 单向链表          | 插入、删除 O(1)                                            | 无序   | 可重复     | 不支持随机访问                                               |
| [list](https://github.com/huihut/interview/tree/master/STL#list) | 双向链表          | 插入、删除 O(1)                                            | 无序   | 可重复     | 不支持随机访问                                               |
| [stack](https://github.com/huihut/interview/tree/master/STL#stack) | deque / list      | 顶部插入、顶部删除 O(1)                                    | 无序   | 可重复     | deque 或 list 封闭头端开口，不用 vector 的原因应该是容量大小有限制，扩容耗时 |
| [queue](https://github.com/huihut/interview/tree/master/STL#queue) | deque / list      | 尾部插入、头部删除 O(1)                                    | 无序   | 可重复     | deque 或 list 封闭头端开口，不用 vector 的原因应该是容量大小有限制，扩容耗时 |
| [priority_queue](https://github.com/huihut/interview/tree/master/STL#priority_queue) | vector + max-heap | 插入、删除 O(log<sub>2</sub>n)                             | 有序   | 可重复     | vector容器+heap处理规则                                      |
| [set](https://github.com/huihut/interview/tree/master/STL#set) | 红黑树            | 插入、删除、查找 O(log<sub>2</sub>n)                       | 有序   | 不可重复   |                                                              |
| [multiset](https://github.com/huihut/interview/tree/master/STL#multiset) | 红黑树            | 插入、删除、查找 O(log<sub>2</sub>n)                       | 有序   | 可重复     |                                                              |
| [map](https://github.com/huihut/interview/tree/master/STL#map) | 红黑树            | 插入、删除、查找 O(log<sub>2</sub>n)                       | 有序   | 不可重复   |                                                              |
| [multimap](https://github.com/huihut/interview/tree/master/STL#multimap) | 红黑树            | 插入、删除、查找 O(log<sub>2</sub>n)                       | 有序   | 可重复     |                                                              |
| [unordered_set](https://github.com/huihut/interview/tree/master/STL#unordered_set) | 哈希表            | 插入、删除、查找 O(1) 最差 O(n)                            | 无序   | 不可重复   |                                                              |
| [unordered_multiset](https://github.com/huihut/interview/tree/master/STL#unordered_multiset) | 哈希表            | 插入、删除、查找 O(1) 最差 O(n)                            | 无序   | 可重复     |                                                              |
| [unordered_map](https://github.com/huihut/interview/tree/master/STL#unordered_map) | 哈希表            | 插入、删除、查找 O(1) 最差 O(n)                            | 无序   | 不可重复   |                                                              |
| [unordered_multimap](https://github.com/huihut/interview/tree/master/STL#unordered_multimap) | 哈希表            | 插入、删除、查找 O(1) 最差 O(n)                            | 无序   | 可重复     |                                                              |

## 迭代器失效

对容器的操作影响了元素的存放位置，称为迭代器失效。

- 序列式容器

  - 调用 erase() 或 insert() ，当前位置到容器末尾元素的所有迭代器全部失效；
  - 如果容器扩容，重新开辟内存，原来容器底层内存上所保存的迭代器全部失效。

  解决办法：利用 erase 方法可以返回下一个有效的迭代器 `it=vec.erase(it)`

- 链表式容器

  删除当前迭代器，仅仅会使当前的迭代器失效，因为底层是链表实现。

  解决办法：

  - 在 erase 时，递增当前迭代器 `list.erase(it++)`；
  - 利用 erase 方法可以返回下一个有效的迭代器 `it=vec.erase(it)`

- 关联式容器

  删除当前迭代器，仅仅会使当前的迭代器失效，因为底层是红黑树实现。

  解决办法：在 erase 时，递增当前迭代器 `map.erase(it++)`; (erase 操作不会返回下一个有效的迭代器)。

## 红黑树

### 特征（STL源码剖析）

红黑树是一种自平衡二叉查找树。

- 每个节点要么是黑色，要么是红色；
- 根节点是黑色；
- 若节点为红，其子节点必须为黑；
- 任一节点至NULL（树尾端）的任何路径，包含的黑节点数量相同。

### 调整

新节点为 X，父节点为 P，祖父节点为 G，伯父节点为 S， 曾祖父节点为 GG。

新插入节点必为叶子节点，故必为红，因为若为黑则违反第四条规则。因此若插入位置的父节点为黑，则直接插入，若为红则需调整树：

- 状况1：S 为黑且 X 为外侧插入。

  P，G 做一次单旋转，并改变 P，G 颜色；

- 状况2：S 为黑且 X 为内测插入。

  先对 P，X 做一次单旋转，并改变 G，X 颜色，再对 G 做一次单旋转；

- 状况3：S 为红且 X 为外侧插入。

  先对 P，G 做一次单旋转，并改变 X 的颜色。若 GG为黑，则完成，若 GG 为红见状况4；

- 状况4：S 为红且 X 为外侧插入。

  先对 P，G 做一次单旋转，并改变 X 的颜色。若 GG 为红，则持续往上做，直到不再父子连红。

### 区别

和平衡二叉树的区别

> 平衡二叉树：它是一个空树或它的左右两个子树的高度差的绝对值不超过 1，并且左右两个子树都是一颗平衡二叉树。

- 红黑树对于平衡性的要求没有平衡二叉树那么严格，在与平衡二叉树的时间复杂度相差不大的情况下，保证每次插入最多只需三次旋转就能达到平衡，维护成本更低，效率更高。

## iterator

作为容器和算法的连接器，所谓的”泛型指针“，可用于对相应的容器进行元素遍历。

## vector

向量（Vector）是一个封装了动态大小数组的顺序容器。

### 实现原理

- 底层是一段连续的线性内存空间
- 内部有三个迭代器
  - _Myfirst 指向 vector 容器对象的起始字节；
  - _Mylast 指向当前最后一个元素的末尾字节；
  - _Myend 指向整个 vector 容器所占内存空间的末尾字节。

- 当大小和容量相等（size == capacity）即满载时，若再添加元素需扩容，机制如下：

### 扩容机制

以 push_back() 将新元素插入到 vector 尾端时，会先检查是否还有备用空间，如果有就直接在备用空间上构造函数，若没有备用空间了，就扩充空间（重新配置、移动数据、释放原空间）。

以原大小的 1.5 倍或 2 倍另外配置一块较大空间，然后将原内容拷贝过去，才开始在原内容后构造新元素，并释放原空间。

（VS 里扩容机制是 1.5 倍扩容，刚开始是 4； gcc 里面是 2 倍扩容）

### [] 和 .at() 的区别

[] 不做边界检查，.at() 会做边界检查；

> operator[] 不做边界检查， 哪怕越界了也会返回一个引用，当然这个引用是错误的引用，如何不小心调用了这个引用对象的方法，会直接导致应用退出。而由于at会做边界检查，如果越界，会抛出异常，应用可以try catch这个异常，应用还能继续运行。

### push_back() 和 emplace_back() 的区别

- push_back() 向容器尾部添加元素时，首先会创建这个元素，然后再将这个元素拷贝或者移动到容器中；
- emplace_back() 在实现时，则是直接在容器尾部创建这个元素，省去了拷贝或移动元素的过程。

### 调用 clear() 

把 size 设置成 0， capacity 不变。

### 回收 vector 空间

- 和一个空 vector swap

  ```cpp
  vector<int>().swap(v);
  v.swap(vector<int>());
  ```

- clear() 后调用 shrink_to_fit()

  C++ 函数 **std::vector::shrink_to_fit()** 请求容器减小其容量以适应其大小。baifubai

## deque

### 实现原理

deque 的底层主要有两个数据结构：中控器和缓存区。其中：

缓冲区由一段一段的定量的连续空间构成，当需要在 deque 前端或尾端增加新的空间时，便配置一段连续定量的空间，串联在 deque 的头端或者尾端。

中控器是一块连续的内存空间，其中每一个元素都是一个指针，指向缓冲区中的一段连续内存空间，以此来维护 deque 内存空间整体连续的假象。

> deque 是由一段一段的定量的连续空间构成。一旦有必要在 deque 前端或者尾端增加新的空间，便配置一段连续定量的空间，串接在 deque 的头端或者尾端。
>
> deque 最大的工作就是维护这些分段连续的内存空间的整体性的假象，并提供随机存取的接口，避开了重新配置空间，复制，释放的轮回，代价就是复杂的迭代器架构。
> 既然 deque 是分段连续内存空间，那么就必须有中央控制，维持整体连续的假象，数据结构的设计及迭代器的前进后退操作颇为繁琐。
>
> deque 采取一块所谓的 map（不是 STL 的 map 容器）作为主控，这里所谓的 map 是一小块连续的内存空间，其中每一个元素（此处成为一个结点）都是一个指针，指向另一段连续性内存空间，称作缓冲区。缓冲区才是 deque的存储空间的主体。

<img src="E:\Desktop\转码\面经回答\images\STL\deque.png" style="zoom:67%;" />

## unordered_map

以键值对 (pair) 的形式存储数据，存储的各个键值对的键互不相同且不允许被修改。当数据存储位置发生冲突时，选用“链地址法”

当使用无序容器存储键值对时，会先申请一整块连续的存储空间，来存储各个链表的头节点指针，各个链表的节点存储各键值。

存储过程：

- 将键的值带入哈希函数，得到哈希值；
- 将哈希值用桶的数量整除，得出键值应存储到的桶编号；
- 建立新节点存储链接到相应桶上（发生冲突用比较函数解决）。

## 哈希冲突

### 原因

哈希函数产生的哈希值是有限的，而数据可能比较多，导致经过哈希函数处理后仍然有不同的数据对应相同的值。

### 影响因素

- 装填因子（装填因子=数据总数 / 哈希表长）；
- 哈希函数；
- 处理冲突的方法。

### 解决方法

- 线性探测：使用哈希函数计算出的哈希值如果已经有元素占用了，则往后一次寻找，直到找到一个未被占用的哈希值；
- 开链：每个表格维护一个list，如果哈希函数计算出的格子相同就按顺序存在这个list中；
- 再散列：发生冲突时使用另一种哈希函数再计算，直到不冲突；
- 公共溢出区：一旦哈希函数计算的结果相同就放入公共溢出区。

# 数据结构

## 十大排序算法

[十大排序 | 菜鸟教程 (runoob.com)](https://www.runoob.com/w3cnote/bubble-sort.html)

#### 冒泡排序

```cpp
void bubble_sort(vector<int>& nums, int n) {
    bool swapped;
    for(int i = 1; i < n; ++i) {
        swapped = false;
        for(int j = 1; j < n - i + 1; ++j) {
            if(nums[j] < nums[j - 1]) {
                swap(nums[j], nums[j - 1]);
                swapped = true;
            }
        }
        if(!swapped) {
            break;
        }
    }
}
```

#### 选择排序

```cpp
void select_sort(vector<int>& nums) {
	int n = nums.size();
    for(int i = 0; i < n - 1; ++i) {
        int minn = i;
        for(int j = i + 1; j < n; ++j) {
            if(nums[j] < nums[minn]) {
                minn = j;
            }
        }
        swap(nums[i], nums[minn]);
    }
}
```

#### 插入排序

```cpp
void insertion_sort(vector<int>& nums, int n) {
    for(int i = 0; i < n; ++i) {
        for(int j = i; j > 0 && nums[j] < nums[j - 1]; --j) {
            swap(nums[j], nums[j - 1]);
        }
    }
}
```

#### 归并排序

```cpp
void merge_sort(vector<int>& nums, int l, int r, vector<int>& temp) {
    if(l + 1 >= r) {
        return;
    }
    int m = l + (r - l) / 2;
    merge_sort(nums, l, m, temp);
    merge_sort(nums, m, r, temp);
    int p = l, q = m, i = l;
    while(p < m || q < r) {
        if(q >= r || (p < m && nums[p] <= nums[q])) {
            temp[i++] = nums[p++];
        }else {
            temp[i++] = nums[q++];
        }
    }
    for(i = l; i < r; ++i) {
        nums[i] = temp[i];
    }
}
```

#### 快速排序

```cpp
void quick_sort(vector<int>& nums, int l, int r) {
    if(l + 1 >= r) {
        return;
    }
    int first = l, last = r, key = nums[first];
    while(first < last) {
        while(first < last && nums[last] >= key) {
            --last;
        }
        nums[first] = nums[last];
        while(first < last && nums[first] <= key) {
            ++first;
        }
        nums[last] = nums[first];
    }
    nums[first] = key;
    quick_sort(nums, l, first);
    quick_sort(nums, first + 1, r);
}
```

#### 稳定性和复杂度

排序前后两个相等的数相对位置不变，则算法稳定。

 冒泡和归并是稳定的；选择、插入、快速和堆是不稳定的。

![](E:\Desktop\转码\面经回答\images\数据结构\十大排序.png)

## 二叉树

### 前序遍历

```cpp
vector<int> preOrder(TreeNode* root) {
    stack<TreeNode*> st;
    vector<int> res;
    if(root == nullptr) return res;
    st.push(root);
    while(!st.empty()) {
        TreeNode* node = st.top();
        st.pop();
        res.push_back(node -> val);
        st.push(node -> right);
        st.push(node -> left);
    }
    return res;
}
```

### 中序遍历

```cpp
vector<int> inorder(TreeNode* root) {
    stack<TreeNode*> st;
    vector<int> res;
    if(root == nullptr) return res;
    TreeNode* cur = root;
    while(cur != nullptr || !st.empty()) {
        if(cur != nullptr) {
            st.push(cur);
            cur = cur -> left;
        }else {
            cur = st.top();
            st.pop();
            res.push_back(cur -> val);
            cur = cur -> right;
        }
    }
    return res;
}
```

### 后序遍历

```cpp
vector<int> postorder(TreeNode* root) {
    stack<TreeNode*> st;
    vector<int> v;
    while(root || st.size()) {
        while(root) {
            v.push_back(root -> val);
            st.push_back(root -> left);
            st = st -> right;
        }
        root = st.top();
        st.pop();
    }
    reverse(v.begin(), v.end());
    return v;
}
```

## 图论

```cpp
int g[N][N];
int dist[N];
bool st[N];

int dijkstra() {
    memset(dist, 0X3f, sizeof(dist));
    dist[1] = 0;
    for(int i = 0; i < n - 1; ++i) {	//需要遍历 n - 1 个点
        int t = -1;
        for(int j = 1; j <= n; ++j) {
            if(!st[j] && (t == -1 || dist[j] < dist[t])) {
                t = j;
            }
        }
        for(int j = 1; j <= n; ++j) {
            if(g[t][j]) {
                dist[j] = min(dist[j], dist[t] + g[t][j]);
            }
        }
        st[t] = true;
    }
    if(dist[n] == 0X3f3f3f3f) return -1;
    return dist[n];
}
```



# 计算机网络

## 名词

**MSS(Maximum Segment Size)，最大报文长度**

收发双方协商通信时每一个报文段所能承载的最大数据长度。TCP 报文的最大长度。

**MTU(Maximum Transmission Unit)，最大传输单元**

一个网络包的最大长度，以太网中一般为 1500 字节。IP 报文的最大长度。

![](./images/计算机网络/MTU+MSS.webp)

**RTT(Round-Trip Time)，往返时延**

表示从发送端发送数据开始，到发送端收到来自接收端的确认（接收端收到数据后便立即发送确认），总共经历的时延。

**RTO(Retransmission Timeout)，超时重传时间**

**MSL(Maximum Segment Lifetime)，最长报文段寿命**

是任何报文在网络上存在的最长的最长时间，超过这个时间报文将被丢弃。

**TTL(time to live)，生存时间**

这个生存时间是由源主机设置设置初始值但不是但不是存在的具体时间，而是一个IP数据报可以经过的最大路由数，每经过一个路由器，它的值就减1，当此值为0则数据报被丢弃，同时发送ICMP报文通知源主机。

## 模型

<img src="E:\Desktop\转码\面经回答\images\计算机网络\网络模型.png" style="zoom:67%;" />

### TCP/IP 六层模型

- **应用层** ：为特定应用程序提供数据传输服务，例如 HTTP、DNS 等协议。数据单位为报文。；
- **传输层** ：为进程提供通用数据传输服务。由于应用层协议很多，定义通用的传输层协议就可以支持不断增多的应用层协议。运输层包括两种协议：传输控制协议 TCP，提供面向连接、可靠的数据传输服务，数据单位为报文段；用户数据报协议 UDP，提供无连接、尽最大努力的数据传输服务，数据单位为用户数据报。TCP 主要提供完整性服务，UDP 主要提供及时性服务；
- **网络层** ：为主机提供数据传输服务。而传输层协议是为主机中的进程提供数据传输服务。网络层把传输层传递下来的报文段或者用户数据报封装成分组；
- **虚拟层：**为服务达到虚实结合，以假乱真。
- **数据链路层** ：网络层针对的还是主机之间的数据传输服务，而主机之间可以有很多链路，链路层协议就是为同一链路的主机提供数据传输服务。数据链路层把网络层传下来的分组封装成帧；
- **物理层** ：考虑的是怎样在传输媒体上传输数据比特流，而不是指具体的传输媒体。物理层的作用是尽可能屏蔽传输媒体和通信手段的差异，使数据链路层感觉不到这些差异。

### OSI 七层模型作用及协议

[OSI七层协议和各种协议介绍 ](https://www.jianshu.com/p/e62440f97874)

- 应用层：为特定应用程序提供数据传输服务；DNS(域名系统)、HTTP(超文本传输协议)、FTP(文件传输协议)、SMTP(简易邮件传输协议)
- 表示层：数据压缩、加密以及数据描述，这使得应用程序不必关心在各台主机中数据内部格式不同的问题；JPEG、MP4
- 会话层：建立及管理会话；NFS(网络文件系统)、RPC(远程过程调用协议)；
- 传输层：为进程提供通用数据传输服务；TCP(传输控制协议)、UDP(用户数据报协议)
- 网络层：为主机提供数据传输服务；ICMP(网间控制报文协议)、IP(网际互连协议)、ARP(地址解析协议)
- 数据链路层：同一链路的主机提供数据传输服务；MAC
- 物理层：在传输媒体上传输数据比特流；RJ45

## HTTP

### HTTP 格式

**请求**

![](E:\Desktop\转码\面经回答\images\计算机网络\HTTP 请求格式.png)

**响应**

![](E:\Desktop\转码\面经回答\images\计算机网络\HTTP 响应格式.png)

### **首部字段**

- 通用首部字段（General Header Fields）请求报文和响应报文两方都会使用的首部。
  - Cache-Control：控制缓存的行为；
  - Connection：连接管理；
  - Date：创建报文的日期时间；
  - Transfer-Encoding：指定报文主体的传输编码方式。
- 请求首部字段（Request Header Fields）从客户端向服务器端发送请求报文时使用的首部。补充了请求的附加内容、客户端信息、响应内容相关优先级等信息。
  - Host：指定资源所在服务器；
  - If-Match：比较实体标记（ETag）；
  - If-Modified-Since：比较资源的更新时间；
  - User-Agent：http 客户端程序的信息。
- 响应首部字段（ Response Header Fields）从服务器端向客户端返回响应报文时使用的首部。补充了响应的附加内容，也会要求客户端附加额外的内容信息。
  - ETag：资源的匹配信息；
  - Location：令客户端重定向至指定 URI。
- 实体首部字段（Entity Header Fields）针对请求报文和响应报文的实体部分使用的首部。补充了资源内容更新时间等与实体有关的信息。
  - Content-Length：实体主体的大小；
  - Content-Encoding：实体主体适用的编码方式；
  - Content-Type：实体主体的媒体类型；
  - Expires：实体主体过期的日期时间；
  - Last-Modified：资源的最后修改日期时间。

### 默认端口号

HTTP 80

### 浏览器从输入 URL 开始到页面显示内容，中间发生了什么？

- 浏览器解析 URL ，生成 HTTP 请求信息；
- DNS 解析域名，获取 IP 地址；
  - 查询浏览器域名缓存；
  - 查询操作系统域名缓存；
  - 查询 hosts 缓存；
  - 查询本地 DNS 服务器；（以上若查到可直接返回）
  - 查询根域名服务器；
  - 查询顶级域名服务器；
  - 查询权威服务器；
  - 权威服务器返回本地DNS服务器。
- 将 HTTP 传输工作交给协议栈，将 HTTP 请求拆分，依次加上 TCP -> IP -> MAC 头部
- 网卡 -> 交换机（MAC） -> 路由器（IP）等硬件传输给服务器
- 服务器返回数据：
  - 如果是 HTTP 强制缓存且在有效期内，不再向服务器发请求；
  - 如果是 HTTP 协商缓存且在有效期内，服务器返回 304 ，直接从浏览器获取数据；
  - 如果不在有效期内服务器返回 200，返回新数据；
  - 返回重定向 301 302，浏览器再按照重定向的地址重新发送请求；
  - 如果请求的参数有问题，服务器端返回404；
  - 如果服务器端挂了返回500
- 浏览器解析 HTML；
- 浏览器布局渲染。

### HTTP 状态码

| 分类 | 分类描述                                         |
| ---- | ------------------------------------------------ |
| 1**  | 提示信息，服务器收到请求，需要请求者继续执行操作 |
| 2**  | 成功，操作被成功接收并处理                       |
| 3**  | 重定向，资源位置变动，需要客户端重新发送请求     |
| 4**  | 客户端错误，请求包含语法错误或无法完成请求       |
| 5**  | 服务器错误，服务器在处理请求的过程中发生了错误   |

- 2**
  - 200 OK：成功状态码；
  - 204 No Content：成功状态码，但响应头没有 body 数据；
  - 206 Partial Content：表示响应返回的 body 数据并不是资源的全部。
- 3**
  - 301 Moved Permanently：永久重定向；
  - 302 Found：临时重定向；
  - 304 Not Modified：缓存重定向，告诉客户端可以继续使用缓存资源。
- 4**
  - 400 Bad Request：客户端请求的报文有错误；
  - 403 Forbidden：服务器禁止访问资源；
  - 404 Not Found：请求的资源在服务器上不存在或未找到。
- 5**
  - 500 Internal Server Error：服务器发生错误；
  - 501 Not Implemented：请求功能暂不支持；
  - 502 Bad Gateway：服务器作为网关或代理时工作正常，访问后端服务器发生了错误；
  - 503 Service Unavailable：服务器忙。

### GET 和 POST 的区别

- GET 用来获取数据，而 POST 提交或修改数据；
- GET 具有幂等性，POST 不具有；（幂等：多次执行相同操作，结果都是相同的）
- GET 请求会被浏览器主动缓存，POST 请求不会被浏览器主动缓存，可手动设置缓存；
- GET 请求参数位置在 URL 中，URL 只支持 ASCII 字符；POST 请求参数在报文体中，可以是任意格式。
- GET的参数会附加在url中 ，以 " ？ "分割url和传输数据，各个参数用 "&"连接，而post会把参数放在http请求体中；
- GET 有长度限制（2048 字节），而 POST 没有；
- GET 参数是显式的，而 POST 参数式隐式的。

安全：请求方法不会破坏服务器上的资源；

幂等：多次执行相同的操作，结果都是相同的。

### HTTP 常见头部字段

**请求头字段**

- Host 字段：当前请求的域名；
- Accept：客户端希望获得资源的类型；
- Accept-Encoding：客户端支持的压缩算法；
- User-Agent：用户代理。

**响应头字段**

- Content-Length：HTTP 消息体长度；

- Connection：客户端是否希望使用长连接；

  ```
  Connection: Keep-Alive
  ```

- Content-Type：服务端返回资源类型，可以带上使用的编码格式；

- Content-Encoding：返回资源的压缩格式。

### HTTP Keep-Alive 和 TCP Keepalive 的区别

- HTTP 的 Keep-Alive 也叫 HTTP 长连接，该功能是由「应用程序」实现的，可以使得用同一个 TCP 连接来发送和接收多个 HTTP 请求/应答，减少了 HTTP 短连接带来的多次 TCP 连接建立和释放的开销。
- TCP 的 Keepalive 也叫 TCP 保活机制，该功能是由「内核」实现的，当客户端和服务端长达一定时间没有进行数据交互时，内核为了确保该连接是否还有效，就会发送探测报文，来检测对方是否还在线，然后来决定是否要关闭该连接。

### 长连接和短链接

- 长连接（long connnection），指在一个连接上可以连续发送多个数据包，在连接保持期间，如果没有数据包发送，需要双方发链路检测包，若超过一定时间没有任何数据交互，服务端会主动断开这个连接。
- 短连接（short connnection），是相对于长连接而言的概念，指的是在数据传送过程中，只在需要发送数据时才去建立一个连接，数据发送完成后则断开此连接，即每次连接只完成一项业务的发送。

### 长连接原理

[HTTP长连接实现原理 - 掘金 (juejin.cn)](https://juejin.cn/post/6923887573861564423)

HTTP 长连接基于的是 TCP 长连接，TCP 长连接基于 TCP 保活机制。

首先保活机制的工作原理就是，通过在服务器端设置一个保活定时器，当定时器开始工作后就定时的向网络通信的另一端发出保活探测的TCP报文，如果接收到了ACK报文，那么就证明对方存活，可以继续保有连接；否则就证明网络存在故障。

### HTTP 1.0 -> HTTP 1.1 -> HTTP 2 -> HTTP 3

HTTP 1.0 -> HTTP 1.1

- 使用长链接；

  > 使用长连接的方式改善了 HTTP/1.0 短连接造成的性能开销。

- 支持管道。

  > 支持管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。

HTTP 1.1 -> HTTP 2

- 二进制格式：

  HTTP 1.X 是纯文本形式的报文；而 HTTP 2.0 头信息和数据体都采用了二进制格式；

- 并发传输

  HTTP 1.X 基于请求-响应模型，同一连接中，HTTP 完成一个事务才能处理下一个事务，会造成队头阻塞。

  HTTP 2.0 同一连接中，不同的 HTTP 请求用独一无二的 Stream ID 来区分，接收端可以通过 Stream ID 有序组装成 HTTP 请求。

- 头部压缩

  客户端和服务器同时维护了一张头信息表，包含所有字段及对应索引号，发送时直接发送索引号，即避免了重复头部的传输，又减小了需要传输的大小；

- 服务器推送

  如果客户端请求了 HTML 文件，服务端会主动将它的依赖文件一起返回。

HTTP 2 -> HTTP 3

把下层的 TCP 协议改成了基于 UDP 的 QUIC 协议。特点：

- 无队头阻塞；
- 更快的连接建立；
- 连接迁移。

### HTTPS 加解密的过程

HTTPS 采用混合加密。对数据进行对称加密，对称加密所需使用的密钥进行非对称加密。

**两个阶段**

- 证书认证阶段

  使用非对称加解密算法对数据传送阶段的对称加解密密钥进行加密和解密；

- 数据传送阶段

  通过证书认证阶段获取到目标服务器的对称加解密密钥，对数据进行加密传送给服务器。

**涉及四个密钥**

- CA 机构的公钥：验证数字证书；
- 服务端的公钥；
- 服务端的私钥；
- 客户端生成的随机私钥。

**六个步骤**

- 客户端向服务器发送 HTTPS 请求，连接到服务器 443 端口；
- 服务器将自己的数字证书（包含公钥）发送给客户端；
- 客户端收到数字证书后，采用 CA 机构公钥验证证书合法性，若非法则中断传输，若合法则生成一个随机值，用作数据传输阶段给数据对称加密的密钥，然后用数字证书中的公钥加密这个随机值密钥。

第一次 HTTP 请求结束；

- 客户端第二次向服务器发起 HTTP 请求，将对称加密密钥的密文发送给服务器；
- 服务器收到客户端发来的对称加密密钥密文，通过使用非对称加密中的私钥解密密文，得到数据传送阶段的对称加密密钥。然后将客户端请求数据通过对称密钥加密，发送给客户端；
- 客户端收到服务端发送的密文，通过对称密钥进行解密，得到数据明文。

第二次 HTTP 请求结束。

### HTTP 和 HTTPS 的区别

- HTTP 是超文本传输协议，明文传输，不安全；HTTPS 在 HTTP 层和 TCP 层中间加入了 SSL/TLS 安全协议，加密传输，安全；
- HTTP只需一次 TCP 三次握手，而 HTTPS 在 TCP  三次握手之后，还需进行 SSL/TLS 握手；
- HTTP的默认端口号为80，而HTTPS的默认端口号为443；
- HTTPS 需要向 CA （权威证书机构）申请数字证书。

**HTTPS缺点**

- 握手阶段耗时；
- HTTPS 效率没有 HTTP 高，部分内容无需加密，浪费计算机资源；
- HTTPS 证书需购买，功能越强大的越贵；
- HTTPS 的加密并不能阻止某些网络攻击，如黑客攻击、拒绝服务攻击。

### HTTPS 解决了 HTTP 的哪些问题

- 窃听风险；
- 篡改风险；
- 冒充风险。

### HTTPS 如何建立连接？

当客户端向服务器端请求数据的时候，服务器大概率会将客户端重定向到该服务器的 443 端口，进行新的TCP连接，此时服务器会返回一个证书文件，而不是响应报文体。此时客户端验证证书文件紧接创建对称密钥，之后重新和服务器建立 TLS 连接，当服务器返回 ACK 确认之后，连接正式建立。

### 对称加密和非对称加密

- 对称加密：加密和解密使用同一种密钥。

  加密解密使用同一个密钥，如何确立密钥的信息需要在网络上传输，数据包被拦截后很危险；

- 非对称加密：加密和解密使用不同的密钥，一把作为公开的公钥，另一把作为私钥，公钥加密的信息，只有私钥才能解密，钥加密的信息只有公钥才能解密。

  公钥公开，私钥自存不需要在网络上传输，安全。

## TCP

### TCP 格式

<img src="./images/计算机网络/TCP.webp" style="zoom:50%;" />

- *ACK*：该位为 `1` 时，「确认应答」的字段变为有效，TCP 规定除了最初建立连接时的 `SYN` 包之外该位必须设置为 `1` 。
- *RST*：该位为 `1` 时，表示 TCP 连接中出现异常必须强制断开连接。
- *SYN*：该位为 `1` 时，表示希望建立连接，并在其「序列号」的字段进行序列号初始值的设定。
- *FIN*：该位为 `1` 时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双方的主机之间就可以相互交换 `FIN` 位为 1 的 TCP 段。

### 如何保证可靠性？

校验和、序列号/确认应答号、超时重传、连接管理、流量控制、拥塞控制等方法。

- 校验和：TCP将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化；
- 序列号：TCP给发送的每一个报文段都进行编号，接收方对报文段进行排序，把有序数据传送给应用层，TCP的接收端会丢弃重复的数据；
- 确认应答号：如果收到的数据报报文段的检验和没有差错，就确认收到，如果有差错，TCP就丢弃这个报文段和不确认收到此报文段；
- 超时重传：当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段；
- 流量控制：TCP 连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失；
- 拥塞控制：当网络拥塞时，减少数据的发送。

### 三次握手

#### TCP三次握手过程是怎么样的？

<img src="\images\计算机网络\TCP三次握手.png" style="zoom:67%;" />

- 一开始，客户端和服务器都处于`CLOSE`状态。首先服务器主动监听某个端口，处于`LISTEN`状态；
- 客户端随机初始化序列号`client_isn`，并置于TCP首部序列号字段；把`SYN`标志置1；把第一个SYN报文发送给服务端，后客户端处于`SYN_SENT`状态；
- 服务端收到客户端SYN报文后，随机初始化序列号`server_isn`，并置于TCP首部序列号字段；其次把TCP首部确认应答号字段填入`client_isn + 1`；把`SYN`和`ACK`标志置1；将该报文发给客户端，后服务器处于`SYN_RCVD`状态；
- 客户端回复应答报文，TCP首部确认应答号字段填入`server_isn + 1`；把`ACK`标志置1；将该报文发给服务端后，客户端处于`ESTABLISHED`状态。（可携带数据）；
- 服务端收到客户端应答报文，进入`ESTABLISHED`状态。

#### 为什么是三次握手？不是两次、四次？

- 阻止历史连接的初始化（主要原因）；
- 同步双方的初始序列号（可以重置序列号）；
- 避免资源浪费（防止冗余连接）。

**不是两次和四次的原因：**

- 两次握手：无法防止历史连接的建立，会造成双方资源的浪费，无法可靠的同步双方序列号；

> 两次握手情况下，网络阻塞，客户端没有收到ACK报文，服务端会建立大量连接。

- 四次握手：三次握手就已经理论上可以建立可靠连接，所以不需要使用更多的通信次数。

### 四次挥手

#### TCP 四次挥手过程是怎么样的？

<img src="\images\计算机网络\TCP四次挥手.png" style="zoom: 67%;" />

- 客户端打算关闭连接，此时会发送一个 TCP 首部 `FIN` 标志位被置为 `1` 的报文，也即 `FIN` 报文，之后客户端进入 `FIN_WAIT_1` 状态。
- 服务端收到该报文后，就向客户端发送 `ACK` 应答报文，接着服务端进入 `CLOSE_WAIT` 状态。
- 客户端收到服务端的 `ACK` 应答报文后，之后进入 `FIN_WAIT_2` 状态。
- 等待服务端处理完数据后，也向客户端发送 `FIN` 报文，之后服务端进入 `LAST_ACK` 状态。
- 客户端收到服务端的 `FIN` 报文后，回一个 `ACK` 应答报文，之后进入 `TIME_WAIT` 状态
- 服务端收到了 `ACK` 应答报文后，就进入了 `CLOSE` 状态，至此服务端已经完成连接的关闭。
- 客户端在经过 `2MSL` 一段时间后，自动进入 `CLOSE` 状态，至此客户端也完成连接的关闭。

#### 为什么挥手需要四次

- 关闭连接时，客户端向服务端发送 `FIN` 时，仅仅表示客户端不再发送数据了但是还能接收数据。
- 服务端收到客户端的 `FIN` 报文时，先回一个 `ACK` 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 `FIN` 报文给客户端来表示同意现在关闭连接。

从上面过程可知，**服务端通常需要等待完成数据的发送和处理，所以服务端的 `ACK` 和 `FIN` 一般都会分开发送**，因此是需要四次挥手。

#### 说一说 TIME_WAIT

TCP连接第四次挥手结束时，主动关闭方进入TIME_WAIT状态，此时主动关闭方会等待 2MSL（最大报文生存期）才会回到 CLOSED 状态。

**为什么需要 TIME_WAIT**

- 保证被动关闭连接的一方，能被正确的关闭；

  等待足够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭。

- 防止历史连接中的数据，被后面相同四元组的连接错误的接收。

  2MSL 足以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的。

#### CLOSE_WAIT

产生CLOSE_WT的原因一般是对方关闭了连接，但是自身还在读取数据或者传输数据，没有关闭连接。

### 超时重传

**概念**

TCP 每发送一条报文，就会启动定时器，当超过设定时间，没有收到对方的 ACK 确认应答报文，就会重发该报文。

**RTO**

- RTO 超时重传时间应略大于 RTT 报文往返时间。RTO 计算由计算平滑的 RTT 和 计算平滑的 RTT 与最新 RTT 的差距决定；
- 每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。

### 快速重传

 当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。

### 滑动窗口

 流量控制中的窗口会持续的向前滑动，因此这个窗口被称为滑动窗口，窗口大小指示**无需等待确认应答，而可以继续发送数据的最大值**。

通常由接收方的窗口大小决定。

- 发送方的滑动窗口

  ![](\images\计算机网络\发送方滑动窗口.png)

  - `SND.WND`：表示发送窗口的大小（大小是由接收方指定的）；
  - `SND.UNA`（*Send Unacknoleged*）：是一个绝对指针，它指向的是已发送但未收到确认的第一个字节的序列号，也就是 #2 的第一个字节；
  - `SND.NXT`：也是一个绝对指针，它指向未发送但可发送范围的第一个字节的序列号，也就是 #3 的第一个字节。

- 接受方的滑动窗口

  ![](\images\计算机网络\接收方滑动窗口.png)

  - `RCV.WND`：表示接收窗口的大小，它会通告给发送方；
  - `RCV.NXT`：是一个指针，它指向期望从发送方发送来的下一个数据字节的序列号，也就是 #3 的第一个字节。

### 流量控制

基于滑动窗口机制，让「发送方」根据「接收方」的实际接收能力控制发送的数据量。例如：

### 拥塞控制

目的：拥塞控制就是防止太多的数据进入到网络中，使网络中的路由器或者链路不会过载。

<img src="\images\计算机网络\拥塞避免.png" style="zoom: 80%;" />

四个算法：

- 慢启动（slow-start）

  初始时先把拥塞窗口 cwnd 设置为一个最大报文段 MSS 的值，每当传输的报文段首次被确认就增加一个 MSS；

- 拥塞避免（congestion avoidance）：当拥塞窗口 cwnd 超过慢启动门限 ssthresh 就会进入拥塞避免算法，每个 RTT 只将 cwnd 的值增加一个 MSS；

- 拥塞发生

  拥塞发生也即发生数据包重传，重传机制有两种：

  - 超时重传
    - ssthresh 设为 cwnd / 2；
    - cwnd 重置为 1MSS。
  - 快速重传
    - ssthresh 设为 cwnd / 2；
    - cwnd = cwnd / 2 + 3 MMS；
    - 进入快速恢复。

- 快速恢复

  - 对收到的每个冗余 ACK，cwnd 的值增加一个 MSS；
  - 最终对丢失报文段的一个 ACK 到达时，TCP 再降低 cwnd 为 ssthreash 后进入拥塞避免状态。

### 粘包

多条数据段当成一条数据段处理。

本质原因：TCP 基于字节流，无法判断发送方报文段边界。

解决方式

- 发送方关闭 Nagle 算法，使用 TCP_NODELAY 选项关闭 Nagle 功能；

- 发送固定长度的消息；

- 用特殊字符标识边界，但会造成边界误判；

- 自定义消息结构

  消息结构：包头 + 数据，包头固定大小，用于存储数据包的整体长度。

###  避免小报文传输

- Nagle 算法

  满足两个条件的任意一个，才能发送数据：

  - 要等到窗口大小 >= `MSS` 并且 数据大小 >= `MSS`；
  - 收到之前发送数据的 `ack` 报文。

- 延迟确认（D-ACK）

  - 当有响应数据要发送时，ACK 会随着响应数据一起立刻发送给对方；
  - 当没有响应数据要发送时，ACK 将会延迟一段时间，以等待是否有响应数据可以一起发送；
  - 如果在延迟等待发送 ACK 期间，对方的第二个数据报文又到达了，这时就会立刻发送 ACK。

### SYN 攻击

<img src=".\images\计算机网络\SYN队列.png" style="zoom: 50%;" />

**概念**

攻击者短时间伪造不同 IP 地址向服务器发送 SYN 报文，服务器回复 ACK + SYN 报文却无法得到 IP 主机的 ACK 应答，进而会占满服务端的**半连接队列**，丢弃后续 SYN 报文，使服务器无法提供服务。

**如何避免？**

- 增大 TCP 半连接队列；

  - 增大 listen() 函数中的 backlog；
  - 增大 net.ipv4.tcp_max_syn_backlog；
  - 增大 net.core.somaxconn。

- 减少 SYN + ACK 重传次数；

  减少重传次数加快处于 SYN_REVC 状态的 TCP 的连接断开。

- 开启 syncookies 功能

  <img src="\images\计算机网络\SYNCookies.png" style="zoom: 50%;" />

  设置参数：net.ipv4.tcp_syncookies

  - 0 值，表示关闭该功能；
  - 1 值，表示仅当 SYN 半连接队列放不下时，再启用它；
  - 2 值，表示无条件开启功能；

  具体过程：

  - 当 「 SYN 队列」满之后，后续服务端收到 SYN 包会计算出一个 `cookie` 值；
  - 服务器将 cookie 值放到第二次握手报文的「序列号」里，回复给客户端；
  - 服务端接收到客户端的 ACK 报文时会检查合法性，如果合法，将该连接对象放入到「 Accept 队列」；
  - 最后应用程序通过调用 `accpet()` 接口，从「 Accept 队列」取出的连接。

### 服务器出现大量 TIME_WAIT 状态的原因有哪些？

TIME_WAIT 是主动关闭连接方才会出现的状态，所以如果服务器出现大量的 TIME_WAIT 状态的 TCP 连接，就是说明服务器主动断开了很多 TCP 连接。

原因：

- HTTP 没有使用长连接；

  解决：让客户端和服务端都开启 HTTP Keep-Alive 机制；

- HTTP 长连接超时（客户端长时间未发送数据，导致服务端主动关闭连接）；

  排查网络问题；

- HTTP 长连接的请求数量达到上限。

  调大 keepalive_requests 参数。

### 服务器出现大量 CLOSE_WAIT 状态的原因？

当服务端出现大量 CLOSE_WAIT 状态的连接的时候，通常都是代码的问题，这时候我们需要针对具体的代码一步一步的进行排查和定位，主要分析的方向就是服务端为什么没有调用 close()。

### 建立连接后，客户端拔掉网线后会怎么样？

- 拔掉网线后，有数据传输

  服务端触发超时重传机制

  - 如果在服务端重传报文的过程中，客户端把网线插了回去，则一切正常；
  - 如果在服务端重传报文的过程中，客户端没有把网线插回去，服务端超时重传报文次数达到一定阈值后，服务端 TCP 连接就会断开；客户端插回网线后向服务端发送数据，由于服务端已经没有与客户端相同四元祖的 TCP 连接了，因此服务端内核就会回复 `RST` 报文，客户端收到后就会释放该 TCP 连接。

- 拔掉网线后，没有数据传输

  - 没有开启 TCP keepalive 机制，则客户端和服务端连接会一直保存；
  - 如果开启 TCP keepalive 机制，会发送探测报文，如果探测报文达到探测次数后就会断开连接。

## UDP

### UDP 怎么样实现可靠的传输

将 TCP 的可靠传输机制在应用层实现。关键点：

- 提供超时重传机制，能避免数据报的丢失；
- 提供确认序列号，保证数据拼接时的正确排序。

详细：

请求端：

- 在 UDP 在数据报定义一个首部，包含确认序列号和时间戳，时间戳用来计算 RTT，进而计算出合适的 RTO；
- 以**等停**的方式发送数据报，即收到确认之后才发送下一个数据报；
- 若超时，重传数据报，RTO 扩大为原来的两倍。

响应端：

- 取下收到数据报首部的确认序列号和时间戳，根据此序列号对已收到的数据报进行排序并丢弃重复的数据报。

## IP

### Ping 的底层原理

基于 ICMP 协议(Internet Control Message Protocol，互联网控制报文协议)

主要功能：

- 确认 IP 包是否送达目标地址；
- 返回发送过程中 IP 包丢失原因；
- 改善网络设置。

### 输入 Ping 后发生了什么？

- 构建一个 ICMP 的请求数据包，然后将数据包和目标 IP 交给 IP 层协议；
- IP 层将源地址、目标地址加上一些控制信息构建成一个 IP 数据包；
- 通过 ARP 映射表找出目标 IP 的 MAC 地址交由数据链路层组成数据帧；
- 目标主机收到数据帧后，取出 IP 数据包交给 IP 层，再取出 ICMP 数据包交给 ICMP 协议，最后构建一个 ICMP 应答数据包回给源主机。

> https://cloudsjhan.github.io/2018/09/16/%E6%8A%80%E6%9C%AF%E5%91%A8%E5%88%8A%E4%B9%8B%E5%BD%93%E4%BD%A0ping%E7%9A%84%E6%97%B6%E5%80%99%EF%BC%8C%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88%EF%BC%9F/

### DNS

#### 解析过程

- 查询浏览器域名缓存；
- 查询操作系统域名缓存；
- 查询 hosts 缓存；
- 查询本地 DNS 服务器；（以上若查到可直接返回）
- 查询根域名服务器；
- 查询顶级域名服务器；
- 查询权威服务器；
- 权威服务器返回本地DNS服务器。

#### DNS 劫持

**概念**

在完成整个域名解析的过程之后，并没有收到本该收到的 IP 地址，而是接收到了一个错误的 IP 地址。

攻击者一般是**修改了本地路由器的 DNS 地址**，从而访问了一个伪造的 DNS 服务器，这个伪造的服务器解析域名的时候返回了一个攻击者精心设计的网站。

**预防**

- 准备多个域名；
- 手动修改 DNS。

### ARP

ARP（Address Resolution Protocol），地址解析协议，用来完成子网中 IP 地址到 MAC 地址的转换。

#### 实现原理

- 主机会在子网中通过广播发送 ARP 请求，请求包含了需转换成 MAC 地址的 IP 地址；
- 同个子网中的所有设备会将 ARP 请求中的 IP 地址与自己的 IP 地址比对，若一致，则将自己的 MAC 地址通过ARP 响应返回给请求主机。

## TCP 和 UDP 的区别

- TCP 面向连接，UDP 是无连接的；
- TCP 提供可靠的服务，也就是说，通过 TCP 连接传送的数据，无差错，不丢失，不重复，且按序到达；UDP 尽最大努力交付，即不保证可靠交付；
- TCP 的逻辑通信信道是全双工的可靠信道；UDP 则是不可靠信道；
- 每一条 TCP 连接只能是点到点的；UDP 支持一对一，一对多，多对一和多对多的交互通信；
- TCP 面向字节流（可能出现黏包问题），实际上是 TCP 把数据看成一连串无结构的字节流；UDP 是面向报文的（不会出现黏包问题）；
- UDP 没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如 IP 电话，实时视频会议等）；
- TCP 首部开销20字节；UDP 的首部开销小，只有 8 个字节。

## TCP 和 UDP 的使用场景

TCP 优点是面向连接可靠交付，适合数据需要准确无误传输的场景。

- 浏览器的 HTTP/HTTPS  协议；
- 邮件服务器的 SMTP 协议。

UDP 优点是快，节省网络资源，适合实时性要求高，允许部分数据丢失的场景。语音、视频、寻址、游戏、广播。

- 语言通话、视频会议；
- DNS 和 ARP 协议。

## Cookie 和 Session 的区别

- cookie 数据存放在客户的浏览器上，session 数据放在服务器上；
- cookie 不是很安全，别人可以分析存放在本地的 cookie 并进行 cookie 欺骗，考虑到安全应使用 session；
- session 会在一定时间内保存在服务器上。当访问增多，会比较占用服务器的性能，考虑到减轻服务器性能方面，应当使用 cookie；
- 单个 cookie 在客户端的限制是 3K，就是说一个站点在客户端存放的 cookie 不能超过 3K；
- 将登录信息等重要信息存放为 session，其他信息如果需要保留，可以放在 cookie 中。

# 设计模式

[FengJungle/DesignPattern: Design pattern demo code (github.com)](https://github.com/FengJungle/DesignPattern)

**感悟：接口就是虚函数或者抽象类（包含虚函数的类）**

## 创建型模式

用于构建对象，以便它们可以从实现系统中分离出来。

### 单例模式（Singleton Pattern）

**定义**

确保一个类只有一个实例，并提供一个全局访问点来访问这个唯一实例。

**要点**

- 这个类只能有一个实例；
- 它必须自己创建这个实例；
- 它必须自己向整个系统提供这个实例。

**优点**

- 保证内存里只有一个实例，减少了内存的开销；
- 避免对资源的多重占用；
- 设置全局访问点，可以优化和共享资源的访问。

**缺点**

- 扩展困难，违背开闭原则；
- 功能代码通常写在一个类中，如果功能设计不合理，则很容易违背单一职责原则。

**实现**

- 私有化构造函数、拷贝构造函数、赋值函数；
- 定义一个私有的本类的静态对象成员；
- 定义一个公共的访问该实例的静态成员方法。

**懒汉模式**

调用时才实例化对象，需加速保证线程安全，影响效率。

```cpp
#include <iostream>
#include <mutex>
using namespace std;
 
class Singleton
{
public:
	static Singleton* getInstance(){  //别漏了 static
		if (instance == NULL){
			m_mutex.lock();
			if (instance == NULL){
				instance = new Singleton();
			}
			m_mutex.unlock();
		}
		return instance;
	}
private:
	Singleton(){}
 
	static Singleton* instance;  //别漏了 static
	static std::mutex m_mutex;	 //别漏了 static
};
 
Singleton* Singleton::instance = NULL;
std::mutex Singleton::m_mutex;
 
#endif //__SINGLETON_H__
```

```cpp
class Singleton
{
private:
	Singleton() { }
	~Singleton() { }
	Singleton(const Singleton &) = delete;
	Singleton & operator = (const Singleton &) = delete;
public:
	static Singleton* GetInstance()
	{
		static Singleton instance;
		return &instance;
	}
};
```

**饿汉模式**

类加载时就实例化对象，线程安全，但浪费内存。

```cpp
class Singleton {
public:
    static Singleton* getInstance() {
        return &instance;
    }
private:
    Singleton(){}
    Singleton(const Singleton &) = delete;
	Singleton & operator = (const Singleton &) = delete;
    ~Singleton(){}
    static Singleton instance;
};
Singleton Singleton::instance; // 在程序入口之前就完成单例对象的初始化。
```

### 抽象工厂模式（Abstract Factory Pattern）

**定义**

提供一个创建一系列相关或相互依赖对象的接口，而无需指定他们具体的类。

**模式结构**

- **抽象工厂（AbstractFactory）**：所有生产具体产品的工厂类的基类，提供工厂类的公共方法；
- **具体工厂（ConcreteFactory）**：生产具体的产品；
- **抽象产品（AbstractProduct）**：所有产品的基类，提供产品类的公共方法；
- **具体产品（ConcreteProduct）**：具体的产品类。

## 结构型模式

用于在许多不同的对象之间形成大型对象结果。

### 适配器模式（Adapter Pattern）

**定义**

将一个类的接口转换成客户希望的另一个接口。适配器模式让那些接口不兼容的类可以一起工作。

**模式结构**

适配器模式分为类适配器和对象适配器。

- **适配器类（Adapter）**：适配器与适配者之间是继承或实现关系；
- **适配者类（Adaptee）**：适配器与适配者之间是关联关系；
- **目标抽象类（Target）**：定义客户所需要的接口。

**类适配器中，适配器类通过继承适配者类**，并重新实现适配者的具体接口来达到适配客户所需要的接口的目的；

**对象适配器中，适配器类通过在类中实例化一个适配者类的对象**，并将其封装在客户所需功能的接口里，达到最终的适配目的。

### 桥接模式（Bridge Pattern）

**定义**

将抽象部分与它的实现部分解耦，使得两者都能够独立变化。

**模式结构**

- **抽象类（Abstraction）**：定义抽象类的接口（抽象接口），抽象类中包含 Implementor 类型的对象，与Implementor 之间有关联关系；
- **实现类（Implementor）**：定义实现类的接口，一般而言，实现类接口只定义基本操作，而抽象类接口还可能会做更多复杂的操作；
- **扩充抽象类（RefinedAbstraction**）：实现在抽象类中定义的接口；
- **具体实现类（ConcreteImplementor）**：实现在实现类中定义的接口。运行时 ConcreteImplementor 将替换父类。

简而言之，在 Abstraction 类中维护一个 Implementor 类指针，需要采用不同的实现方式的时候只需要传入不同的 Implementor 派生类就行了。

## 行为型模式

用于管理对象之间的算法、关系和职责。

### 观察者模式（Observer Pattern）/ 发布-订阅模式

**定义**

定义对象之间的一种一对多的依赖关系，使得每当一个对象状态发生改变时，其相关依赖对象都得到通知并被自动更新。

**模式结构**

- **目标（Subject）**：是被观察的对象，目标中定义了一个观察者的集合，通过 attach() 和 detach() 方法来增删观察者对象。目标声明了通知方法 notify()，用于在自身状态发生改变时通知观察者；
- **具体目标（ConcreteSubject）**：具体目标实现了通知方法 notify()，同时具体目标有记录自身状态的属性和成员方法；
- **观察者（Observer）**：观察者将对接收到的目标发生改变的通知做出自身的反应，抽象层声明了更新方法 update()；
- **具体观察者（ConcreteObserver）**：实现了更新方法 update()，具体观察者中维护了一个具体目标对象的引用（指针），用于存储目标的状态。

# 操作系统

## 硬件结构

### CPU

周期

- 指令周期（Instruction Cycle）：取出并执行一条指令的时间。
- CPU周期：一条指令执行过程被划分为若干阶段，每一阶段完成所需时间。
- 时钟周期（Clock Cycle）：又称震荡周期，是处理操作的最基本单位。
- 对于一个指令周期来说，我们取出一条指令，然后执行它，至少需要两个 CPU 周期。取出指令至少需要一个 CPU 周期，执行至少也需要一个 CPU 周期，复杂的指令则需要更多的 CPU 周期。而一个CPU周期是若干时钟周期之和。

## 内存管理

### 虚拟内存

#### 作用

虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，让程序获得更多的可用内存。 

- 空间独立：由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，所以这些页表是私有的。这就解决了多进程之间物理地址冲突的问题；
- 可以扩充内存：每个进程拥有自己独立的虚拟地址空间，但不需要让进程中所有的页都必须映射到物理内存中，当程序引用到不在物理内存中的页时，由硬件执行必要的内存映射，将缺失的部分装入物理内存并重新执行失败的指令，这也使得有限的内存运行大程序成为可能；
- 安全性强：页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。

#### 区别

- 物理内存是指由于安装内存条而获得的临时储存空间；
- 虚拟内存是计算机系统内存管理的一种技术。

### 分段和分页

#### 分段

用户程序地址空间分成若干个大小不等的段，每段逻辑信息相对完整。段在内存中可以不相邻接，实现离散分配。

**优点**

使程序和数据可以被划分为逻辑上独立的地址空间，有助于共享和保护；

#### 分页

用户程序的地址空间被划分成若干固定大小的页，同时，内存空间分成若干个固定大小的物理块，可将用户程序的任一页映射到内存的任一块。

**优点**

- 解决内存碎片，提高内存利用率；
- 换入换出效率高；
- 用于实现虚拟内存，获得更大的逻辑地址空间。

#### 段页式

将用户程序地址空间分成若干个段，再把每个段分成若个页。

**运行方式**

每个进程设立一张段表，每个分段设立一张页表。

通过段表中段号查到页表地址，再通过页表中页号找到物理起始地址，再通过页内偏移找到物理地址。

**优点**

兼具。

<img src="E:\Desktop\转码\面经回答\images\操作系统\段页式.png" style="zoom:67%;" />

#### TLB

<img src=".\images\操作系统\TLB.png" style="zoom:67%;" />

- TLB（*Translation Lookaside Buffer*），通常称为页表缓存、转址旁路缓存、快表等，专门存放程序最常访问的页表项的 Cache；
- 内存管理单元（*Memory Management Unit*）芯片，它用来完成地址转换和 TLB 的访问与交互。

### 内存布局

<img src="\images\操作系统\内存布局.png" style="zoom:67%;" />

- 代码段，包括二进制可执行代码；
- 数据段，包括已初始化的静态变量和全局变量；
- BSS 段，包括未初始化的静态变量和全局变量；
- 堆段，包括动态分配的内存，从低地址开始向上增长；
- 文件映射段，包括动态库、共享内存等，从低地址开始向上增长；
- 栈段，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 `8 MB`。当然系统也提供了参数，以便我们自定义大小。

### 函数调用流程（栈的变化）

- 开辟栈帧空间；通过帧指针 rbp 和栈指针 rsp
- 函数参数从右至左进行压栈；
- 函数返回地址进行压栈；
- 函数局部变量进行压栈。

### 堆和栈的区别

- 管理方式：栈由编译器自动管理，堆由程序员手动开辟释放；
- 空间大小：栈空间有限，堆几乎没有限制，栈小于堆；
- 碎片：栈不存在碎片问题，频繁分配释放堆会造成内存碎片；
- 拓展方向：栈沿着内存地址减小的方向拓展，堆沿着内存地址增大的方向拓展；
- 分配方式：栈有静态分配和动态分配，静态由编译器分配，动态由malloc函数分配且由编译器释放，堆只有动态分配；
- 分配效率：栈是机器系统提供的数据结构，效率很高，堆是 C/C++ 函数提供的，机制复杂效率低。

|          |                              栈                              |                              堆                              |
| :------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
| 申请方式 |                        自动分配/释放                         |                        手动分配/释放                         |
| 系统响应 | 只要**栈的剩余空间大于所申请的空间**，**系统将为程序提供内存**，否则将报异常提示栈溢出。 | **操作系统有一个记录空间内存地址的链表**，当系统收到程序的申请时，会遍历链表，**寻找第一个空间大于所申请空间的堆节点，然后将节点从内存空闲节点链表中删除，并将该节点的空间分配给程序**。对于大多数操作系统，会在这块内存空间中的首地址处记录本次分配的大小，这样，代码中的delete语句才能正确的释放本内存空间。另外，由于找到的对节点的大小不一定正好等于申请的大小，系统会自动地将多余的那部分重新放入到链表中。 |
|   地址   |               **向低地址拓展**，连续，一般 8MB               |                   **向高地址拓展**，不连续                   |
| 存储内容 | 在函数调用时，第一个进栈的是主函数的中的下一条指令（函数调用的下一个可执行语句）的地址，然后是函数的各个参数。在 C 编译器中，参数是由右往左入栈的（出于可变参数考虑），然后是函数的局部变量。静态变量不入栈。 | 一般是**在堆的头部用一个字节存放堆的大小**。堆中的具体内容由程序员安排。 |

### 栈中存放什么？

[C语言 | C++ 堆栈工作机制 - 腾讯云开发者社区-腾讯云 (tencent.com)](https://cloud.tencent.com/developer/article/1765337?areaSource=103001.1&traceId=FoatMd550SyZykQZSHYJ9)

函数参数、函数局部变量、函数的返回地址、寄存器的值。

> 栈可能会用到 main 函数中已经使用的寄存器，所以将原先寄存器的值记录下来，以便调用完后恢复。

ESP 指针指向栈顶，EBP 指针指向原先 EBP 寄存器的值，向上依次访问函数返回地址和函数参数，向下访问局部变量。

**入栈顺序**

函数参数、函数返回地址、EBP 寄存器原来的值、局部变量、函数中使用到的通用寄存器入栈。

### malloc 

#### 实现原理

- 当开辟的空间小于 128K 时，通过 `brk()` 系统调用从堆分配内存，其主要移动堆顶指针 `_enddata`(此时的 _enddata 指的是 Linux 地址空间中堆段的末尾地址，不是数据段的末尾地址)；
- 当开辟的空间大于 128K 时，通过 `mmap()` 系统调用在文件映射区域分配内存。

其中用 brk() 系统调用分配内存时，会维护一个内存空闲链表，当申请内存空间时，搜索内存空闲链表，找到适配的空闲内存空间，然后将空间分割成两个内存块，一个变成分配块，一个变成新的空闲块。如果没有搜索到，那么就会调用 sbrk() 推进 brk 指针来申请内存空间。

#### malloc 申请的内存，free 释放内存会归还给操作系统吗？

- malloc 通过 **brk()** 方式申请的内存，free 释放内存的时候，**并不会把内存归还给操作系统，而是缓存在 malloc 的内存池中，待下次使用**；
- malloc 通过 **mmap()** 方式申请的内存，free 释放内存的时候，**会把内存归还给操作系统，内存得到真正的释放**。

#### 为什么不全部使用 mmap 来分配内存？

- 因为 mmap 系统调用分配的内存每次释放的时候，都会归还给操作系统，**频繁通过 mmap 分配的内存话，不仅每次都会发生运行态的切换，还会发生缺页中断（在第一次访问虚拟地址后），这样会导致 CPU 消耗较大**。
- malloc 通过 brk() 系统调用在堆空间申请内存的时候，由于堆空间是连续的，所以直接预分配更大的内存来作为内存池，当内存释放的时候，就缓存在内存池中。**等下次在申请内存的时候，就直接从内存池取出对应的内存块就行了，而且可能这个内存块的虚拟地址与物理地址的映射关系还存在，这样不仅减少了系统调用的次数，也减少了缺页中断的次数，这将大大降低 CPU 的消耗。**

#### 既然 brk 那么牛逼，为什么不全部使用 brk 来分配？

随着系统频繁地 malloc 和 free ，尤其对于小块内存，堆内将产生越来越多不可用的碎片，导致“内存泄露”。而这种“泄露”现象使用 valgrind 是无法检测出来的。

### 内存映射

**API**

```cpp
void* mmap(void* addr, size_t length, int prot, int flags, int fd, off_t offset)
```

- addr 代表映射的虚拟内存起始地址；

- length 代表该映射长度；

- prot 设置内存段的访问权限；

  - **PROT_EXEC**，代表该内存映射有可执行权限，可以看成是代码段，通常存储CPU可执行机器码
  - **PROT_READ**，代表该内存映射可读
  - **PROT_WRITE**，代表该内存映射可写
  - **PROT_NONE**，代表该内存映射不能被访问

- flags 描述了该映射的类型；

  **MAP_SHARED**，创建一个共享映射区域

  **MAP_PRIVATE**，创建一个私有映射区域

  **MAP_ANONYMOUS**，创建一个匿名映射区域，该情况只需要传入-1即可

  **MAP_FIXED**，当操作系统以addr为起始地址进行内存映射时，如果发现不能满足长度或者权限要求时，将映射失败，如果非**MAP_FIXED**，则系统就会再找其他合适的区域进行映射

- fd 代表文件描述符：当参数fd不等于0时，内存映射将与文件进行关联，如果等于0，就会变成匿名映射，此时 flags 必为**MAP_ANONYMOUS**

- offset 代表文件内的偏移值。

**过程**

- 进程调用 mmap，在虚拟地址空间中为映射创建虚拟映射区域；
- 调用内核空间的系统调用 mmap，实现文件物理地址和进程虚拟地址的映射关系；
- 进程发起对这片映射空间的访问，引发缺页中断，实现文件内容到物理内存（主存）的拷贝。

### 内存泄漏

#### 定义

内存泄漏（Memory Leak）是指程序中已**动态分配的堆内存**由于某种原因程序未释放或无法释放，造成系统内存的浪费，导致程序运行速度减慢甚至系统崩溃等严重后果。

#### 检测方法

- 查找内存泄漏的应用程序：输入命令 top，按 Shift + M（以内存占用列排序）；

- 进入找到的内存泄露应用程序源码，利用 valgrind 查找泄漏点；

  1.编译程序

  ```shell
  g++ -g -o leak leak.c
  ```

  2.

  ```shell
  valgrind --tool=memcheck --leak-check=full --show-reachable=yes --trace-children=yes    ./leak
  --tool 指定工具；
  –-leak-check=full 指的是完全检查内存泄漏；
  –-show-reachable=yes 是显示内存泄漏的地点；
  –-trace-children=yes 是跟入子进程；
  ```

## 进程、线程与协程

[进程线程面试题总结](https://blog.csdn.net/wujiafei_njgcxy/article/details/77098977)

### 为什么引入进程

实现多个程序的并发执行。

### 进程有多少种状态，如何转换*

**状态**

- 创建：一个进程启动，首先进入创建状态，需要获取系统资源创建进程管理块（PCB：Process Control Block）完成资源分配；
- 就绪：在创建状态完成之后，进程已经准备好，处于就绪状态，但是还未获得处理器资源，无法运行；
- 运行：获取处理器资源，被系统调度，当具有时间片开始进入运行状态。如果进程的时间片用完了就进入就绪状态；
- 阻塞：在运行状态期间，如果进行了阻塞的操作，此时进程暂时无法操作就进入到了阻塞状态；
- 终止：进程结束或者被系统终止，进入终止状态。

**转换**

<img src="\images\操作系统\进程状态转换.png"  />

### 孤儿进程

**孤儿进程是指一个父进程退出后，而它的一个或多个子进程还在运行，那么这些子进程将成为孤儿进程。**

孤儿进程将被 init 进程（进程号为1）所收养，并且由 init 进程对它们完整状态收集工作，孤儿进程一般不会产生任何危害。

### 僵尸进程

僵尸进程是指一个进程使用 fork() 函数创建子进程，如果子进程退出，而父进程并没有调用 wt() 或者 wtpid() 系统调用取得子进程的终止状态，那么子进程的进程描述符仍然保存在系统中，占用系统资源，这种进程称为僵尸进程。

**如何解决**

- 为了防止产生僵尸进程，在 fork() 子进程之后我们都要及时在父进程中使用 wait() 或者 waitpid() 系统调用，等子进程结束后，父进程回收子进程控制块（PCB:Processing Control Block）的资源；
- 当子进程退出的时候，内核都会给父进程一个 SIGCHLD 信号，所以可以建立一个捕获 SIGCHLD 信号的信号处理函数，在函数体中调用 wait() 或 waitpid()，就可以清理退出的子进程以达到防止僵尸进程的目的。

### 写时拷贝

如果有多个调用者（callers）同时请求相同资源（如内存或磁盘上的[数据存储](https://cloud.tencent.com/product/cdcs?from=10680)），他们会共同获取相同的指针指向相同的资源，直到某个调用者试图修改资源的内容时，系统才会真正复制一份专用副本（private copy）给该调用者，而其他调用者所见到的最初的资源仍然保持不变。

例如：Linux 的 fork() 使用写时拷贝（Copy-on-write）页实现。最初内核并不复制整个进程的地址空间，而是让父子进程共享同一个地址空间。只用在需要写入的时候才会复制地址空间，从而使各个进行拥有各自的地址空间。

### 进程调度算法

- **先来先服务（FCFS）调度算法** 先来先去服务调度算法是一种最简单的调度算法，也称为先进先出或严格排队方案。每次调度都是从后备作业（进程）队列中选择**一个或多个最先进入该队列的作业（进程）**，将它们调入内存，为它们分配资源、创建进程，当每个进程就绪后，它加入就绪队列。当前正运行的进程停止执行，选择在就绪队列中存在时间最长的进程运行；
- **短作业优先（SJF）调度算法** 短作业优先（SJF）的调度算法是从后备队列中选择一个或若干个估计运行时间最短的作业（进程），将它们调入内存运行，短进程优先（SPF）调度算法从就绪队列中**选择一个估计运行时间最短的进程**，将处理机分配给它，使之立即执行，直到完成或者发生某件事而阻塞时，才释放处理机；
- **优先级调度算法** 优先级调度算法又称优先权调度算法，该算法既可以用于作业调度，也可以用于进程调度，该算法中的优先级用于描述作业运行的紧迫程度。在作业调度中，优先级调度算法每次**从后备作业队列中选择优先级最髙的一个或几个作业**，将它们调入内存，分配必要的资源，创建进程并放入就绪队列；在进程调度中，优先级调度算法每次从就绪队列中选择优先级最高的进程，将处理机分配给它，使之投入运行。
- **高响应比优先调度算法** 高响应比优先调度算法主要用于作业调度，该算法是对 FCFS 调度算法和 SJF 调度算法的一种综合平衡，同时**考虑每个作业的等待时间和估计的运行时间**。在每次进行作业调度时，先计算后备作业队列中每个作业的响应比，从中选出响应比最高的作业投入运行；
- **时间片轮转调度算法** 时间片轮转调度算法主要适用于分时系统。每次调度时，**把 CPU 分配给队首进程，并令其执行一个时间片**。时间片的大小从几 ms 到几百 ms。当执行的时间片用完时，由一个计时器发出时钟中断请求，调度程序便据此信号来停止该进程的执行，并将**它送往就绪队列的末尾；然后，再把处理机分配给就绪队列中新的队首进程**，同时也让它执行一个时间片；
- **多级反馈队列调度算法** 多级反馈队列调度算法是时间片轮转调度算法和优先级调度算法的综合和发展，通过动态调整进程优先级和时间片大小，多级反馈队列调度算法可以兼顾多方面的系统目标。

### 为什么使用线程

为了解决负载均衡问题，提高 CPU 的利用率。

### 进程和线程的区别

**进程**是运行中的程序或任务；

**线程**是进程中的一条执行流程。

- 本质区别

  进程是资源分配的基本单位，线程是CPU调度的基本单位；

- 内存消耗

  进程有独立的虚拟地址空间，而同一个进程的线程之间共享进程的资源，自身只有栈和寄存器等少量独立的空间；

- 切换开销

  进程切换时，需要切换页表以及打开的各种文件；线程切换时只需保存和设置少量寄存器内容；故进程的上下文切换时间开销远远大于线程上下文切换时间；

- 并发性

  进程的并发性较低，线程的并发性较高；

- 崩溃

  一个进程崩溃后，在保护模式下不会对其他进程产生影响，但是一个线程崩溃会影响所属进程。所以多进程要比多线程健壮。

**占有资源**

| 进程占有的资源                                           | 线程占有的资源               |
| -------------------------------------------------------- | ---------------------------- |
| 地址空间  全局变量  打开的文件  子进程  信号量  账户信息 | 栈  寄存器  状态  程序计数器 |

### 线程和协程的区别

**协程**是一种用户态的轻量级线程，一种非抢占式的任务调度模式，程序可以主动挂起或者恢复执行。

- 线程消耗操作系统资源，协程可以靠编译语言实现，协程比线程更轻量；
- 线程在多核环境下可以做到并行，而协程是为并发而产生；
- 线程进程都是同步机制，而协程是异步机制；
- 线程是抢占式，协程是非抢占式，（需要用户自己释放使用权来切换到其他协程，因此同一时间其实只有一个协程拥有运行权，相当于单线程的能力）；
- 线程数量上千，协程上万。

### 进程上下文切换



### 进程间通信方式

- 匿名管道

  ```cpp
  #include <unistd.h>
  int pipe(int fd[2]);
  ```

  fd[0]  用于读，fd[1]  用于写。

  **限制：**

  - 数据是无格式的流且大小受限，通信方式是单向的；
  - 只能在父子进程或者兄弟进程中使用。

- 命名管道（FIFO）

  也称为命名管道，去除了管道只能在父子进程中使用的限制。

  ```cpp
  #include <sys/stat.h>
  int mkfifo(const char *path, mode_t mode);
  int mkfifoat(int fd, const char *path, mode_t mode);
  ```

  - 管道写入数据均缓存在内核中；
  - 遵循先进先出原则。

- 消息队列

  - 保存在内核的消息链表；
  - 写入和读取都需要经过用户态和内核态的拷贝。

  相比于 FIFO，消息队列具有以下优点：

  - 消息队列可以独立于读写进程存在，从而避免了 FIFO 中同步管道的打开和关闭时可能产生的困难；
  - 避免了 FIFO 的同步阻塞问题，不需要进程自己提供同步方法；
  - 读进程可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收。

- 信号量

  - 是一个整型的计数器，用于为多个进程提供对共享数据对象的互斥访问；
  - 两个原子操作：P 操作和 V 操作。

- 信号

  对于**异常情况下的工作模式**，就需要用到信号的方式来通知线程。

  信号是进程间通信机制中**唯一的异步通信机制**，因为可以在任何时候发送信号给某一进程，一旦有信号产生，我们就有下面这几种，用户进程对信号的处理方式：

  - 执行默认操作：Linux 对每种信号都规定了默认操作；
  - 捕捉信号：为信号定义一个信号处理函数；
  - 忽略信号：不做任何处理。

- 共享内存

  - 允许多个进程共享同一个给定的存储区；
  - 因为数据不需要在进程之间复制，所以这是最快的一种 IPC；
  - 需要使用信号量来同步对共享内存的访问。

- Socket

  与其它通信机制不同的是，它可用于不同机器间的进程通信。

### 线程间通信方式

* 锁机制：包括互斥锁/量（mutex）、读写锁（reader-writer lock）、自旋锁（spin lock）、条件变量（condition）
  * 互斥锁/量（mutex）：提供了以排他方式防止数据结构被并发修改的方法。
  * 读写锁（reader-writer lock）：允许多个线程同时读共享数据，而对写操作是互斥的。
  * 自旋锁（spin lock）与互斥锁类似，都是为了保护共享资源。互斥锁是当资源被占用，申请者进入睡眠状态；而自旋锁则循环检测保持者是否已经释放锁。
* 条件变量（condition）：可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。
* 信号量机制 (Semaphore)
  * 无名线程信号量
  * 命名线程信号量
* 信号机制 (Signal)：类似进程间的信号处理
* 屏障（barrier）：屏障允许每个线程等待，直到所有的合作线程都达到某一点，然后从该点继续执行。

### 条件变量

条件变量总是与互斥锁一起使用，先上锁，然后对条件变量进行检测，若条件为假，则线程阻塞，同时释放互斥锁；若条件变为真，则将线程唤醒，同时再次获取互斥锁。

在没达到预设条件时候释放锁，当条件成立再次获取锁。

**使用**

```cpp
#include <iostream>
#include <thread>
#include <mutex>
#include <condition_variable>

std::deque<int> q;
std::mutex mu;
std::condition_variable cond;

void function_1() //生产者
{
    int count = 10;
    while (count > 0) 
    {
        std::unique_lock<std::mutex> locker(mu); //自动 lock
        q.push_front(count);
        locker.unlock();
        cond.notify_one();  // Notify one waiting thread, if there is one.
        std::this_thread::sleep_for(std::chrono::seconds(1));
        count--;
    }
}

void function_2() //消费者
{
    int data = 0;
    while (data != 1) 
    {
        std::unique_lock<std::mutex> locker(mu);
        while (q.empty())
            cond.wait(locker); // Unlock mu and wait to be notified
        data = q.back();
        q.pop_back();
        locker.unlock();
        std::cout << "t2 got a value from t1: " << data << std::endl;
    }
}
int main() 
{
    std::thread t1(function_1);
    std::thread t2(function_2);
    t1.join();
    t2.join();
    return 0;
}
```

```cpp
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <pthread.h>

//链表的结点
struct msg
{
    int num; 
    struct msg *next; 
};
 
struct msg *head = NULL;    //头指针
struct msg *temp = NULL;    //节点指针

//静态方式初始化互斥锁和条件变量
pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;
pthread_cond_t has_producer = PTHREAD_COND_INITIALIZER;
 
void *producer(void *arg)
{
    while (1)   //线程正常不会解锁，除非收到终止信号
	{
        pthread_mutex_lock(&mutex);         //加锁

        temp = malloc(sizeof(struct msg));
        temp->num = rand() % 100 + 1;
        temp->next = head;
        head = temp;                        //头插法
        printf("---producered---%d\n", temp->num);

        pthread_mutex_unlock(&mutex);       //解锁
        pthread_cond_signal(&has_producer); //唤醒消费者线程
        usleep(rand() % 3000);              //为了使该线程放弃cpu,让结果看起来更加明显。
    }
 
    return NULL;
}
 
void *consumer(void *arg)
{
    while (1)       //线程正常不会解锁，除非收到终止信号
	{
        pthread_mutex_lock(&mutex);     //加锁
        while (head == NULL)            //如果共享区域没有数据，则解锁并等待条件变量（线程阻塞）
	    {
            pthread_cond_wait(&has_producer, &mutex);   //我们通常在一个循环内使用该函数
            //唤醒后，又为 mutex 上锁
        }
        temp = head;
        head = temp->next;
        printf("------------------consumer--%d\n", temp->num);
        free(temp);                     //删除节点，头删法
        temp = NULL;                    //防止野指针
        pthread_mutex_unlock(&mutex);   //解锁

        usleep(rand() % 3000);          //为了使该线程放弃cpu,让结果看起来更加明显。
    }
 
    return NULL;
}
 
int main(void)
{
    pthread_t ptid, ctid;
    srand(time(NULL));      //根据时间摇一个随机数种子

    //创建生产者和消费者线程
    pthread_create(&ptid, NULL, producer, NULL);
    pthread_create(&ctid, NULL, consumer, NULL);

    //主线程回收两个子线程
    pthread_join(ptid, NULL);
    pthread_join(ctid, NULL);
 
    return 0;
}
```

### 共享内存

**概念**

共享内存是进程间通信的一种方式。进程将同一段物理内存连接到自己的地址空间，进而不同进程都可以访问共享内存中的地址。

**优点**

是效率最高的进程间通信方式，无需系统调用或者切换至内核，也避免了对数据的不必要复制；

**缺点**

共享内存没有提供同步机制，故需要保证数据同步。

### 条件变量实现原理

[条件变量(condition variables)实现原理](https://blog.csdn.net/MoonWisher_liang/article/details/110689470)

### 信号量实现原理

## 锁

### 死锁

**定义**

 两个或两个以上的进程在执行过程中，因争夺共享资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。

**产生必要条件**

- 互斥条件：多个进程不能同时使用同一个资源；
- 持有并等待条件：进程 A 在等待资源 2 的同时并不会释放自己已经持有的资源 1；
- 不可剥夺条件：在自己使用完之前不能被其他进程获取；
- 环路等待条件：两个进程获取资源的顺序构成了环形链。

#### 死锁处理方法

**鸵鸟策略**

**死锁检测和死锁恢复**

- 利用抢占恢复；
- 利用回滚恢复；
- 通过杀死进程恢复。

**死锁预防**

破坏四个必要条件中的一个或多个吧。

- 破坏互斥：
- 破坏持有并等待：进程运行之前分配它需要的全部资源；
- 破坏不可剥夺：进程在等不得请求的资源时，释放已拥有的资源；优先级高的进程抢占低优先级进程的资源；
- 破坏环路等待：资源按序分配。

**死锁避免**

- 有序资源分配法：线程 A 和 线程 B 总是以相同的顺序申请自己想要的资源；
- 银行家算法：在进程提出资源申请时，先预判此分配是否会导致系统进入不安全状态。如果会进入不安全状态，就暂时不答应这次请求，让该进程先阻塞等待。

#### 死锁简单代码实现

```cpp
#include <iostream>
#include <thread>
#include <mutex>

std::mutex mtx1, mtx2;

void threadFunc1()
{
    mtx1.lock();
    std::cout << "Thread 1 has acquired mutex 1" << std::endl;

    mtx2.lock();
    std::cout << "Thread 1 has acquired mutex 2" << std::endl;

    mtx2.unlock();
    mtx1.unlock();
}

void threadFunc2()
{
    mtx2.lock();
    std::cout << "Thread 2 has acquired mutex 2" << std::endl;

    mtx1.lock();
    std::cout << "Thread 2 has acquired mutex 1" << std::endl;

    mtx1.unlock();
    mtx2.unlock();
}

int main()
{
    std::thread t1(threadFunc1);
    std::thread t2(threadFunc2);

    t1.join();
    t2.join();

    return 0;
}
```



### 各种锁

- 互斥锁/量（mutex）：提供了以排他方式防止数据结构被并发修改的方法；

- 读写锁（reader-writer lock）：允许多个线程同时读共享数据，而对写操作是互斥的；

  [【C++多线程】读写锁shared_lock/shared_mutex - Chen沉尘 - 博客园 (cnblogs.com)](https://www.cnblogs.com/chen-cs/p/13065948.html)

- 自旋锁（spin lock）与互斥锁类似，都是为了保护共享资源。互斥锁是当资源被占用，申请者进入睡眠状态；而自旋锁则循环检测保持者是否已经释放锁；[(48条消息) c++之理解自旋锁_c++自旋锁_DZGNB的博客-CSDN博客](https://blog.csdn.net/qq_46615150/article/details/114284151)

  实现：

  ```cpp
  class spinlock_mutex {
  private:
      std::atomic_flag flag;
  public:
      spinlock_mutex() : flag (ATOMIC_FLAG_INIT) {}
      void lock() {
          while (flag.test_and_set(memory_order_acquire));
      }
      void unlock() {
          flag.clear(memory_order_release);
      }
  }
  ```

  

### 互斥锁和自旋锁的区别

- 互斥锁在获取不到锁的时候将线程挂起，本质是一个获取锁的系统调用，从用户态切换到内核态，系统调用失败线程休眠；
- 自旋锁获取不到锁的时候进入忙等待，不会主动切换线程，程序始终运行在用户态。

### 乐观锁和悲观锁

- 乐观锁

  乐观锁是先修改同步资源，再验证有没有发生冲突；GIT、SVN 等代码版本控制管理器；

- 悲观锁

  悲观锁是修改共享数据前，都要先加锁，防止竞争；数据库行锁、表锁。

## 调度算法

### 进程调度

### 内存页面置换

**缺页中断**：当程序试图访问已映射在虚拟地址空间中，但是未加载到物理内存中的一个分页时，由 CPU 的内存管理单元（MMU）所发出的中断。

- 最佳页面置换算法（OPT）：置换未来最长时间不访问的页面；
- 先进先出置换算法（FIFO）：选择在内存驻留时间很长的页面置换；
- 最近最久未使用的置换算法（LRU）：选择最长时间没有被访问的页面进行置换；
- 最不常用置换算法（LFU）：选择访问次数最少的页面进行置换。

### 磁盘调度

## 系统调用

**概念**：内核中用于实现操作系统各种功能的子程序。

**目的**：管理硬件资源；使应用程序具备更好的兼容性。

**过程**

<img src="E:\Desktop\转码\面经回答\images\操作系统\系统调用过程.png" style="zoom:67%;" />

系统调用后，将系统调用号放入 eax 寄存器，触发中断，由用户态进入内核态，根据中断号查中断向量表，执行中断服务程序 system_call，中断服务程序根据系统调用号查系统调用表，执行系统调用。

Linux 中所有系统调用对应的中断号是 0X80。

### 中断

**概念**：系统外部、系统内部或者现行程序本身若出现紧急事件，计算机立即中止现行程序的运行，自动转入相应的处理程序(中断服务程序)，待处理完后，再返回原来的程序运行。

**分类**

- 硬件中断：直接处理硬件请求，主要负责耗时短的工作，特点是快速执行；
- 软件中断：由内核触发，主要负责耗时较长的工作，特点是延迟执行。

## 文件读取

### 数据从磁盘到内核的整个过程

- 用户进程调用 read 方法，向操作系统发出 I/O 请求，进程进入阻塞状态；
- 操作系统收到请求后，将 I/O 请求发送至 DMA ，然后让 CPU 执行其他任务；
- DMA 将 I/O 请求发送至磁盘；
- 磁盘收到 I/O 请求，把数据从磁盘读取到磁盘控制器的缓冲区，当该缓冲区读满，向 DMA 发起中断信号；
- DMA 收到磁盘信号，将磁盘控制器缓冲区数据拷贝到内核缓冲区中；
- 当 DMA 读取了足够多的数据，就发送中断信号给 CPU；
- CPU 收到中断信号，将数据从内核缓冲区拷贝至用户空间。 

# 编译原理

## 编译过程

<img src="E:\Desktop\转码\面经回答\images\编译原理\编译过程.png" style="zoom:67%;" />

## 动态库和静态库

### 区别

- 命名方式

  - Linux：静态库：libXXX.a；动态库：libXXX.so
  - Windows：静态库：libXXX.lib；动态库：libXXX.dll

- 链接时间

  - 静态库链接在链接阶段，将静态库中的代码整合进目标代码；
  - 动态库链接在运行阶段，加载对应函数的库。

- 制作方式

  - 动态库：`g++ XXX.cpp [-Iinclude] -fPIC -shared -o libXXX.so`
  - 静态库：`1.g++ XXX.cpp -c [-I...] //生成.o文件  2.ar rs libXXX.a XXX.o`

- 链接

  `g++ -L指定库文件路径 -l指定库文件`

### 优缺点

- 静态库
  - 优点：发布程序时无需提供静态库，移植方便，运行速度相对快些；
  - 缺点：静态链接生成的可执行文件体积较大，消耗内存；若使用静态库发生改变，程序必须重新编译；
- 动态库
  - 优点：节省内存并减少页面交换；修改库文件无需重新编译；
  - 缺点：速度慢；发布程序时需要提供动态库。

# 网络编程

## Socket

### 大端字节序和小端字节序（网络字节序和主机字节序）

大端字节序：一个整数的高位字节存储在内存的低地址处，低位字节存储在内存的高地址处；

小端字节序：一个整数的高位字节存储在内存的高地址处，低位字节存储在内存的低地址处。

**如何判断**

```cpp
#include <stdio.h>
void byteorder() {
    union {
        short value;
        char union_bytes[sizeof(short)];
    } test;
    test.value = 0X0102;	//字符串从小到大为地址从低到高
    if((test.union_bytes[0]) == 1) && (test.union_bytes[1] == 2)) {
        printf("big endian\n");
    }else if((test.union_bytes[0]) == 2) && (test.union_bytes[1] == 1)) {
        printf("little endian\n");
    }
}
```

### API

<img src="E:\Desktop\转码\面经回答\images\网络编程\socket.png"  />

- 创建socket

  ```cpp
  #include <sys/types.h>
  #include <sys/socket.h>
  int socket(int domain, int type, int protocol);
  ```

  - domain：确定底层协议族；
    - TCP/IP 协议族：PF_INET (IPv4)；PF_INET6 (IPv6)；
    - UNIX 本地协议族：PF_UNIX；
  - type：确定服务类型；
    - SOCK_STREAM：流服务，TCP；
    - SOCK_DGRAM：数据报服务，UDP；
  - protocol：前两个参数构成的协议集合下，再选择一个具体的协议。通常是唯一的，设为0；
  - 成功返回 socket 文件描述符，失败返回 -1，设置errno。

- 命名socket

  ```cpp
  #include <sys/types.h>
  #include <sys/socket.h>
  int bind(int sockfd, const struct sockaddr* my_addr, socklen_t addrlen);
  ```

  bind 将 my_addr 所指的 socket 地址分配给未命名的 sockfd 文件描述符，addrlen 参数指出该 socket 地址的长度。

- 监听 socket

  ```cpp
  #include <sys/socket.h>
  int listen(int sockfd, int backlog);
  ```

  sockfd 参数指定被监听的 socket；backlog 参数指定内核监听队列的最大长度。

- 接收连接

  ```cpp
  #include <sys/types.h>
  #include <sys/socket.h>
  int accept(int sockfd, struct sockaddr* addr, socklen_t *addrlen);
  ```

  - sockfd：执行过 listen 调用的 监听 socket；
  - addr：获取被接受连接的远端 socket 地址；
  - addrlen：获取 socket 地址参数；
  - 成功返回 connfd，失败返回 -1，设置 errno。

- 发起连接（客户端）

  ```cpp
  #include <sys/types.h>
  #include <sys/socket.h>
  int connect(int sockfd, const struct sockaddr *serv_addr, socklen_t addrlen);
  ```

  - sockfd：socket 系统调用创建的 sockfd，用于唯一标识客户端连接到服务器的连接；
  - sockaddr：服务器监听的 socket 地址；
  - addrlen：指定地址长度。
  - 成功时返回0，失败时返回 -1 ，设置 errno。

- 关闭连接

  ```cpp
  #include <unistd.h>
  int close(int fd);
  ```

  fd 参数指定关闭连接，将 fd 引用计数减一，减为 0 时才真正关闭连接；

  fork() 默认将父进程中打开的 socket 引用计数加 1。

  ```cpp
  #include <sys/socket.h>
  int shutdown(int sockfd, int howto);
  ```

  howto：

  - SHUT_RD：关闭读，socket 接受缓存区数据丢弃；
  - SHUT_WR：关闭写，等待 socket 发送缓冲区发送完成后关闭，期间不可写；
  - SHUT_RDWR：关闭读写。

### 三次握手、四次挥手，分别对应了 socket 哪些函数？

#### 三次握手

<img src="E:\Desktop\转码\面经回答\images\网络编程\三次握手.png"  />

- 客户端调用 connect，向服务端发送 SYN J 报文，connect 进入阻塞状态；
- 服务端收到 SYN J 报文，调用 accept 向客户端发送 SYN K 和 ACK J + 1报文，accept 进入阻塞状态；
- 客户端收到客户端 SYN 和 ACK J + 1 报文，connect 返回，回复请求确认报文 ACK K + 1；
- 服务器收到客户端确认报文 ACK K + 1，accept 返回，三次握手完成。

#### 四次挥手

![](E:\Desktop\转码\面经回答\images\网络编程\四次挥手.png)

- 客户端调用 close 主动关闭连接，向服务端发送 FIN M 报文；
- 服务端收到 FIN M 报文，执行被动关闭，发送 ACK M + 1报文，传递文件结束符给应用进程；
- 带服务端处理完数据后，服务端调用 close 关闭 socket，发送 FIN N 报文；
- 客户端对 FIN N 报文进行确认。

## I/O 模型

Unix 有五种 I/O 模型：

- 阻塞式 I/O
- 非阻塞式 I/O
- I/O 复用（select 和 poll）
- 信号驱动式 I/O（SIGIO）
- 异步 I/O（AIO）

输入操作包括两个阶段：

- 等待数据准备好
- 从内核向进程复制数据

第一步通常涉及等待数据从网络中到达。当所等待数据到达时，它被复制到内核中的某个缓冲区。第二步就是把数据从内核缓冲区复制到应用进程缓冲区。

**同步 I/O 和异步 I/O 的区别**

- 同步 I/O：将数据从内核缓冲区复制到应用进程缓冲区的阶段（第二阶段），应用进程会阻塞。
- 异步 I/O：第二阶段应用进程不会阻塞。

同步 I/O 包括阻塞式 I/O、非阻塞式 I/O、I/O 复用和信号驱动 I/O ，它们的主要区别在第一个阶段。

非阻塞式 I/O 、信号驱动 I/O 和异步 I/O 在第一阶段不会阻塞。

## I/O 复用

### 介绍一下 I/O 多路复用

 I/O 多路复用是一种使得程序能同时监听多个文件描述符的技术，从而提高程序的性能。I/O 多路复用能够在单个线程中，通过监视多个 I/O 流的状态来同时管理多个 I/O 流，一旦检测到某个文件描述符上我们关心的事件发生（就绪），能够通知程序进行相应的处理（读写操作）。 Linux 下实现 I/O 复用的系统调用主要有 select、poll 和 epoll。

### select

#### API

select 允许应用程序监视一组文件描述符，等待一个或者多个描述符成为就绪状态。

```cpp
int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);
```

- nfds 参数指定被监听的文件描述符的总数。

- readfds、writefds 和 exceptfds 参数分别指向可读、可写和异常等事件对应的文件描述符集合。

  fd_set 使用数组实现，数组大小使用 FD_SETSIZE 定义，所以只能监听少于 FD_SETSIZE 数量的描述符。

  ```cpp
  #include <sys/select.h>
  FD_ZERO(fd_set *fdset);
  FD_SET(int fd, fd_set *fdset);
  FD_CLR(int fd, fd_set *fdset);
  int FD_ISSET(int fd, fd_set *fdset);
  ```

- timeout 参数用来设置 select 函数的超时时间。

  ```cpp
  struct timeval {
  	long tv_sec;   //秒
  	long tv_usec;  //微秒
  };
  ```

- select 成功时返回就绪文件描述符的总数；若超时，返回 0；若失败返回 -1 并设置 errno。

#### 原理

- 首先要构造一个关于**文件描述符的列表**，将要监听的文件描述符添加到该列表中，这个文件描述符的列表数据类型为 fd_set，它是一个整型数组，总共是 1024 个比特位，每一个比特位代表一个文件描述符的状态；
- 调用 select() 系统调用，监听该列表中的文件描述符的事件，这个函数是阻塞的，直到这些描述符中的一个或者多个进行 I/O 操作时，该函数才返回，并修改文件描述符的列表中对应的值，0 表示没有检测到该事件，1 表示检测到该事件。函数对文件描述符的监听的操作是由内核完成的；
-  select() 返回时，会告诉进程有多少描述符要进行 I/O 操作，接下来遍历文件描述符的列表进行 I/O 操作。

#### 缺点

- 每次调用select，都需要把 fd 集合从用户态拷贝到内核态；
- 同时每次调用 select 都需要在内核遍历传递进来的所有 fd；
- select 只支持的 1024 个文件描述符数量；
-  文件描述符集合不能重用，因为内核每次检测到事件都会修改，所以每次都需要重置；
- select 返回后，需遍历描述符集合判断就绪事件。

### poll

poll 的功能与 select 类似，也是等待一组描述符中的一个成为就绪状态

```cpp
int poll(struct pollfd *fds, unsigned int nfds, int timeout);
```

- fds 参数是一个 pollfd 结构类型的数组，它指定所有我们感兴趣的文件描述符上发生的可读、可写和异常等事件

  ```cpp
  struct pollfd {
      int fd; 
      short events; //注册的事件
      short events; //实际发生实际，由内核填充
  }
  ```

- nfds 参数指定被监听事件集合 fds 大小

- timeout 参数指定超时值，单位是毫秒。为 -1 时，永远阻塞

- 返回值与 select 意义相同

### epoll

#### **API**

```cpp
#include <sys/epoll.h>
int epoll_create(int size);
```

- size 告诉内核事件表需要多大
- 返回文件描述符标识内核事件表

```cpp
int epoll_ctl(int epfd, int op, int fd, struct epoll_event* event);
```

- fd 参数是要操作的文件描述符
- op 参数指定操作类型
  - EPOLL_CTL_ADD：往事件表注册 fd 上的事件；
  - EPOLL_CTL_MOD：修改 fd 上的注册事件；
  - EPOLL_CTL_DEL：删除 fd 上的注册事件。
- event 参数指定事件。

```cpp
int epoll_wait(int epfd, struct epoll_event* events, int maxevents, int timeout);
```

- epfd 参数指定内核事件表
- 检测到事件就将所有就绪的事件从内核事件表中复制到 events 指向的数组中
- maxevents 参数指定最多监听多少个事件。

#### **工作模式**

- LT 模式

  当 epoll_wait() 检测到描述符事件到达时，将此事件通知进程，进程可以不立即处理该事件，下次调用 epoll_wait() 会再次通知进程。是默认的一种模式，并且同时支持 blocking 和 no-blocking socket。

- ET 模式

  和 LT 模式不同的是，通知之后进程必须立即处理事件，下次再调用 epoll_wait() 时不会再得到事件到达的通知。

  很大程度上减少了 epoll 事件被重复触发的次数，因此效率要比 LT 模式高。只支持 No-Blocking socket，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。

应用场景：ET 实时传输；LT  吞吐量大，多路复用。

> ### ET
>
> - ET(edge-triggered)是高速工作方式，只支持no-block-socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知。请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核不会发送更多的通知(only once).
> - 优点：每次内核只会通知一次，大大减少了内核资源的浪费，提高效率。
> - 缺点：不能保证数据的完整。不能及时的取出所有的数据。
> - 应用场景： 处理大数据。使用non-block模式的socket。
>
> ### LT
>
> - LT(level triggered)是缺省的工作方式，并且同时支持block和no-block socket.在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的，所以，这种模式编程出错误可能性要小一点。传统的select/poll都是这种模型的代表．
> - 优点：当进行socket通信的时候，保证了数据的完整输出，进行IO操作的时候，如果还有数据，就会一直的通知你。
> - 缺点：由于只要还有数据，内核就会不停的从内核空间转到用户空间，所有占用了大量内核资源，试想一下当有大量数据到来的时候，每次读取一个字节，这样就会不停的进行切换。内核资源的浪费严重。效率来讲也是很低的。

#### 说一说 epoll 的原理（牛客）

[EPOLL原理详解](https://www.cnblogs.com/Hijack-you/p/13057792.html)

<img src="\images\网络编程\epoll原理.png" style="zoom: 67%;" />

epoll 是一种更加高效的 IO 复用技术，epoll 的使用步骤及原理如下： 

1. 调用 epoll_create() 会在内核中创建一个 eventpoll 结构体数据，称之为 epoll 对象，在这个结构体中有 3 个比较重要的数据成员
   - rbr：红黑树，用于维护包装了 epoll 需监控文件描述符信息的 epitem 结构；
   - 就绪列表 rdlist：双向链表，存放监测到就绪事件的文件描述符信息；
   - 等待队列 wq：用于保存对某一个 epoll 对象调用 epoll_wait() 的所有进程。
2.  调用 epoll_ctrl() 向 epoll 对象中添加、删除、修改要监听的文件描述符及事件，此时，内核会将需要监听的文件和事件信息包装在 epitem 结构里，维护在红黑树上，同时，给这个文件描述符注册一个回调函数ep_poll_callback, 当网卡收到数据后软中断会调用这个回调函数把这个文件描述符信息加入到 rdllist 中，同时唤醒 eventpoll 等待队列 wq 中的进程。
3. 调用 epoll_wait() 会将进程加入 eventpoll 的等待队列 wq，阻塞进程；监测到描述符事件就绪时，唤醒进程。

#### 内核原理

[十个问题理解 Linux epoll 工作原理 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/378892166)

[(48条消息) EPOLL内核原理极简图文解读_epoll 唤醒_LeechanXBlog的博客-CSDN博客](https://blog.csdn.net/linkedin_38454662/article/details/73337208)

epoll_ctl() 用于向内核注册新的描述符或者是改变某个文件描述符的状态。已注册的描述符在内核中会被维护在一棵红黑树上，通过回调函数内核会将 I/O 准备好的描述符加入到一个链表中管理，进程调用 epoll_wait() 便可以得到事件完成的描述符。

每个被加入 epoll 监控的文件描述符会被包装在 epitem 结构里，维护在一个红黑树上，同时给该文件描述符注册一个回调函数 ep_poll_callback，通过该回调函数将事件就绪的文件描述符加入 ep->rdlist 管理；进程调用 epoll_wait() 后，被加入 ep->wp 队列等待。

- epitem 需要监听的文件和事件信息，都被包装在 epitem 结构里。每当用户调用 epoll_ctl()新增一个监视文件，都要给这个文件注册一个回调函数 ep_poll_callback, 当网卡收到数据后软中断会调用这个 ep_poll_callback 把这个 epitem 加入到 ep->rdllist 中。
- ep -> wq 是一个等待队列，用来保存对某一个 epoll 实例调用 epoll_wait()的所有进程。
- ep -> poll_wait 是另一个等待队列，当被监视的文件是一个 epoll 类型时，需要用这个等待队列来处理递归唤醒。
- ep -> rdlist 是 epoll 实例中包含就绪事件的 fd 组成的链表。

#### 惊群效应

多个进程等待在 ep -> wq 上，事件触发后所有进程都被唤醒，但只有其中一个进程能够成功继续执行的现象。

**如何解决惊群**：设置 EPOLLEXCLUSIVE 选项和 SO_REUSEPORT 选项。

- EPOLLEXCLUSIVE 是在唤起进程阶段起作用，只唤起排在队列最前面的 1 个进程；
-  SO_REUSEPORT 是在分配连接时起作用，相当于每个进程自己都有一个独立的 epoll 实例，内核来决策把连接分配给哪个 epoll。

### 比较

- select 默认只能监听少于 1024 个描述符，而 poll 和 epoll 没有描述符限制；
- poll 和 epoll 提供了更多的事件类型；
- select 和 poll 每次调用都需要将全部描述符从进程缓冲区复制到内核缓冲区，epoll 只需要将描述符从进程缓冲区向内核缓冲区拷贝一次，并且进程不需要通过轮询来获得事件完成的描述符；
- 如果一个线程对某个描述符调用了 select 或者 poll，另一个线程关闭了该描述符，会导致调用结果不确定；一个线程调用了 epoll_wait() 另一个线程关闭了同一个描述符也不会产生像 select 和 poll 的不确定情况；
- epoll 仅适用于 Linux OS。

### 应用场景

- select：timeout 参数精度为微秒，而 poll 和 epoll 为毫秒，因此 select 更加适用于实时性要求比较高的场景；
- poll：没有最大描述符数量的限制，如果平台支持并且对实时性要求不高，应该使用 poll 而不是 select；
- epoll：只需要运行在 Linux 平台上，有大量的描述符需要同时轮询，并且这些连接最好是长连接。

# 并发编程

### std::thread

[C++ std::thread | 菜鸟教程 (runoob.com)](https://www.runoob.com/w3cnote/cpp-std-thread.html)

### atomic

### 三个交替打印 ABC

```cpp
#include<stdio.h>
#include<unistd.h>
#include<pthread.h>
#include<semaphore.h>
#include<stdlib.h>

sem_t sem[3];//信号量
int count1=10,count2=10,count3=10;//控制输出次数，不设置可能无限输出
void* fun1(void* arg)
{
     while(count1>0)//while(1)则无限输出
     {
           sem_wait(&sem[0]);
           write(1,"1",1);
           sem_post(&sem[1]);
	   count1--;
     }
}
void* fun2(void* arg)
{
     while(count2>0)
     {
          sem_wait(&sem[1]);
          write(1,"2",1);
          sem_post(&sem[2]);
	  count2--;
     }
}
void* fun3(void* arg)
{
      while(count3>0)
      {
          sem_wait(&sem[2]);
          write(1,"3",1);
          sem_post(&sem[0]);
	  count3--;
      }
}
int main()
{
      pthread_t id[3];

      sem_init(&sem[0],0,1);
      sem_init(&sem[1],0,0);
      sem_init(&sem[2],0,0);
 
 	  //创建三个线程
      pthread_create(&id[0],NULL,fun1,NULL);
      pthread_create(&id[1],NULL,fun2,NULL);
      pthread_create(&id[2],NULL,fun3,NULL);
 
      pthread_join(id[0],NULL);
      pthread_join(id[1],NULL);
      pthread_join(id[2],NULL);
 
      sem_destroy(&sem[0]);
      sem_destroy(&sem[1]);
      sem_destroy(&sem[2]);

      printf("\n");
      exit(0);
}
```

```cpp
#include <iostream>
#include <thread>
#include <condition_variable>
std::mutex mtx;
std::condition_variable cv;
int ready = 0;
void PrintString_1()
{
        std::unique_lock<std::mutex> lk(mtx);
        int cnt = 0;
        while(cnt<10)
        {
                while(ready != 0)
                        cv.wait(lk);
                std::cout<<"A"<<std::endl;
                ready = 1;
                cnt++;
                cv.notify_all();
        }
}

void PrintString_2()
{
        std::unique_lock<std::mutex> lk(mtx);
        int cnt = 0;
        while(cnt<10)
        {
                while(ready != 1)
                        cv.wait(lk);
                std::cout<<"B"<<std::endl;
                ready = 2;
                cnt++;
                cv.notify_all();
        }
}

void PrintString_3()
{
        std::unique_lock<std::mutex> lk(mtx);
        int cnt = 0;
        while(cnt<10)
        {
                while(ready != 2)
                        cv.wait(lk);
                std::cout<<"C"<<std::endl;
                ready = 0;
                cnt++;
                cv.notify_all();
        }
}

int main()
{
        std::thread  t1(PrintString_1);
        std::thread  t2(PrintString_2);
        std::thread  t3(PrintString_3);
        t1.join();
        t2.join();
        t3.join();
        return 0;
}
```



# Linux 命令

[Linux 命令大全 | 菜鸟教程 (runoob.com)](https://www.runoob.com/linux/linux-command-manual.html)

## 系统管理

### ps（process status）

显示当前进程的状态。

```shell
ps [options] [--help]
```

- -A 列出所有的进程

- -w 显示加宽可以显示较多的资讯

- -au 显示较详细的资讯

- -aux 显示所有包含其他使用者的进程

- au(x) 输出格式 :

  ```shell
  USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND
  ```

  - USER: 行程拥有者
  - PID: pid
  - %CPU: 占用的 CPU 使用率
  - %MEM: 占用的记忆体使用率
  - VSZ: 占用的虚拟记忆体大小
  - RSS: 占用的记忆体大小
  - TTY: 终端的次要装置号码 (minor device number of tty)
  - STAT: 该行程的状态:
    - D: 无法中断的休眠状态 (通常 IO 的进程)
    - R: 正在执行中
    - S: 静止状态
    - T: 暂停执行
    - Z: 不存在但暂时无法消除
    - W: 没有足够的记忆体分页可分配
    - <: 高优先序的行程
    - N: 低优先序的行程
    - L: 有记忆体分页分配并锁在记忆体内 (实时系统或捱A I/O)
  - START: 行程开始时间
  - TIME: 执行的时间
  - COMMAND:所执行的指令

```
ps -ef | grep 进程关键字
```

查找指定进程格式。

### pstree（display a tree of processes）

将所有进程以树状图显示，树状图将会以 pid (如果有指定) 或是以 init 这个基本进程为根 (root)，如果有指定使用者 id，则树状图会只显示该使用者所拥有的进程。

```shell
pstree [-a] [-c] [-h|-Hpid] [-l] [-n] [-p] [-u] [-G|-U] [pid|user]
pstree -V
```

- -a 显示该进程的完整指令及参数, 如果是被记忆体置换出去的进程则会加上括号
- -c 如果有重覆的进程名, 则分开列出（预设值是会在前面加上 *）

### top

实时显示进程的动态。

```shell
top [-] [d delay] [q] [c] [S] [s] [i] [n] [b]
```

- d : 改变显示的更新速度，或是在交谈式指令列( interactive command)按 s
- q : 没有任何延迟的显示速度，如果使用者是有 superuser 的权限，则 top 将会以最高的优先序执行
- c : 切换显示模式，共有两种模式，一是只显示执行档的名称，另一种是显示完整的路径与名称
- S : 累积模式，会将己完成或消失的子进程 ( dead child process ) 的 CPU time 累积起来
- s : 安全模式，将交谈式指令取消, 避免潜在的危机
- i : 不显示任何闲置 (idle) 或无用 (zombie) 的进程
- n : 更新的次数，完成后将会退出 top
- b : 批次档模式，搭配 "n" 参数一起使用，可以用来将 top 的结果输出到档案内

### 进程状态

| 状态 | 说明                                                         |
| :--: | :----------------------------------------------------------- |
|  R   | running or runnable (on run queue) 正在执行或者可执行，此时进程位于执行队列中。 |
|  D   | uninterruptible sleep (usually I/O) 不可中断阻塞，通常为 IO 阻塞。 |
|  S   | interruptible sleep (waiting for an event to complete) 可中断阻塞，此时进程正在等待某个事件完成。 |
|  Z   | zombie (terminated but not reaped by its parent) 僵死，进程已经终止但是尚未被其父进程获取信息。 |
|  T   | stopped (either by a job control signal or because it is being traced) 结束，进程既可以被作业控制信号结束，也可能是正在被追踪。 |

## 内存管理

- free：用于显示内存状态。

  ```shell
  free [-bkmotV][-s <间隔秒数>]
  ```

  - -b 　以Byte为单位显示内存使用情况。
  - -k 　以KB为单位显示内存使用情况。
  - -m 　以MB为单位显示内存使用情况。
  - -h 　以合适的单位显示内存使用情况，最大为三位数，自动计算对应的单位值。
  - -o 　不显示缓冲区调节列。
  - -s<间隔秒数> 　持续观察内存使用状况。
  - -t 　显示内存总和列。
  - -V 　显示版本信息。

## 网络管理

- netstat：用于显示网络状态。

  ```shell
  netstat [-acCeFghilMnNoprstuvVwx][-A<网络类型>][--ip]
  ```

  - -a或--all 显示所有连线中的Socket。
  - -A<网络类型>或--<网络类型> 列出该网络类型连线中的相关地址。
  - -c或--continuous 持续列出网络状态。
  - -C或--cache 显示路由器配置的快取信息。
  - -e或--extend 显示网络其他相关信息。
  - -F或--fib 显示路由缓存。
  - -g或--groups 显示多重广播功能群组组员名单。
  - -h或--help 在线帮助。
  - -i或--interfaces 显示网络界面信息表单。
  - -l或--listening 显示监控中的服务器的Socket。
  - -M或--masquerade 显示伪装的网络连线。
  - -n或--numeric 直接使用IP地址，而不通过域名服务器。
  - -N或--netlink或--symbolic 显示网络硬件外围设备的符号连接名称。
  - -o或--timers 显示计时器。
  - -p或--programs 显示正在使用Socket的程序识别码和程序名称。
  - -r或--route 显示Routing Table。
  - -s或--statistics 显示网络工作信息统计表。
  - -t或--tcp 显示TCP传输协议的连线状况。
  - -u或--udp 显示UDP传输协议的连线状况。
  - -v或--verbose 显示指令执行过程。
  - -V或--version 显示版本信息。
  - -w或--raw 显示RAW传输协议的连线状况。
  - -x或--unix 此参数的效果和指定"-A unix"参数相同。
  - --ip或--inet 此参数的效果和指定"-A inet"参数相同。

## 应用场景

### **判断文件是否存在指定字符串**

```shell
grep "hello" file.txt
```

如果文件中包含该字符串，则 `grep` 命令将输出包含该字符串的行。如果文件中不包含该字符串，则 `grep` 命令不会输出任何内容。

### 查看端口

- ```shell
  lsof -i : 端口号
  ```

  查看指定端口运行程序及运行连接。

- ```shell
  netstat -tunlp | grep 端口号
  ```

  用于显示 tcp，udp 的端口和进程等相关情况。

  - -t：显示 TCP 端口；
  - -u：显示 UDP 端口
  - -n：不进行 DNS 轮询，显示 IP；
  - -l：仅显示 listen 套接字；
  - -p：显示进程标识符和程序名称。

### 检测远程主机端口是否打开

```shell
telnet ip地址 端口
```

### 查看 CPU 使用率

```shell
top
vmstat	实时输出系统各种资源的使用情况
mpstat	实时监测多处理器系统上每个 CPU 的使用情况。	
```

### CPU 占用过高如何排查

- top 命令，然后 shift + P 按照 CPU 排序，找到占用 CPU 过高的进程；
- ps 命令，找到占用 CPU 高的线程；
- 将线程 ID 转换为 16 进制；
- 使用 jstack 打印堆栈信息。

### 查看文件和文件夹大小

- 查看文件夹大小

  ```shell
  du -sh
  查看当前目录下的总大小
  ```

- 查看文件大小

  ```shell
  ls
  h   以M，G的格式展现
  S   从大到小排列文件（大写 S）
  l   展示详细信息
  a  显示隐藏文件
  ```

### 查看网络状态

- `ping`
- `traceroute`：用于显示数据包到主机间的路径。

# 数据库

## ACID

- 原子性（atomicity）：事务中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节，若事务在执行过程中发生错误，会被**回滚**到事务开始前的状态，通过 undo log（回滚日志） 来保证。
- 一致性（consistency）：是指事务操作前和操作后，数据满足**完整性约束**，数据库保持一致性状态，通过持久性+原子性+隔离性来保证；
- 隔离性（isolation）：数据库允许并发事务对数据库进行操作，隔离性可以防止**并发事务交叉执行**导致的数据不一致问题，通过 **MVCC（多版本并发控制） 或锁机制**来保证；
- 持久性（durability）：事务处理结束后，对数据的修改就是永久的，即便**系统故障也不会丢失**，通过redo log （重做日志）来保证。

## 三大范式

* 第一范式（1NF）：属性（字段）是最小单位不可再分。
* 第二范式（2NF）：满足 1NF，每个非主属性完全依赖于主键（消除 1NF 非主属性对码的部分函数依赖）。
* 第三范式（3NF）：满足 2NF，任何非主属性不依赖于其他非主属性（消除 2NF 非主属性对码的传递函数依赖）。
* 鲍依斯-科得范式（BCNF）：满足 3NF，任何非主属性不能对主键子集依赖（消除 3NF 主属性对码的部分和传递函数依赖）。
* 第四范式（4NF）：满足 3NF，属性之间不能有非平凡且非函数依赖的多值依赖（消除 3NF 非平凡且非函数依赖的多值依赖）。

## 比较

### MySQL 为什么不用跳表？

**跳表比 B+ 树层级更高**，需要更多的磁盘IO。

### Redis 为什么不用 B+ 树？

Redis是基于内存的数据库，不用考虑磁盘IO问题，采用跳表，**不用考虑 B+ 树页分裂、维护各种索引页**等问题。

# MySQL

## B+ 树

定义：m 阶 B+ 树的结构定义如下：

- 每个节点最多有m个子节点
- 除根节点外，每个节点至少有m/2个子节点，注意如果结果除不尽，就向上取整，比如5/2=3。
- 根节点要么是空，要么是独根，否则至少有2个子节点
- 有k个子节点的节点包含有k个元素
- 叶节点的高度一致。

### B 树和 B+ 树的区别

都是多路平和查找树，B+ 树是 B树 的一种变体，有着比 B 树更高的查询性能。一个 m 阶 B 树具有如下特征：

1、根节点至少有两个子节点；

2、每个中间节点都包含 k-1个元素和k个孩子，其中m/2<=k<=m；

3、每一个叶子节点都包含k-1个元素，其中m/2<=k<=m；

4、所有的叶子节点都位于同一层；

5、每个节点中的元素从小到大排列，节点当中k-1个元素正好是k个孩子包含的元素的值域划分。

B+树和B树有一些共同特征，但是B+树也具备一些新的特征：

1、有k个子树的中间节点包含有k个元素（B树中是k-1个元素），每个元素不保存数据，只用来索引，所有数据都保存在叶子节点；

2、所有的叶子节点中包含了全部元素的信息，即指向含这些元素记录的指针，且叶子节点本身依关键字的大小自小而大顺序链接；

3、所有的中间节点元素都同时存在于子节点，在子节点元素中是最大（或最小）元素；

4、叶子节点用双向链表连接，方便范围查找。

### 为什么用 B+ 树 不用哈希表

- 哈希表需要将所有数据载入内存，无法实现；
- 哈希表无法进行范围搜索

### 为什么用 B+ 树 不用红黑树

不管平衡二叉查找树还是红黑树，都会随着插入的元素增多，而导致树的高度变高，这就意味着磁盘 I/O 操作次数多，会影响整体数据查询的效率。

### 为什么用 B+ 树 不用 B 树

- **单点查询**：B 树非叶子节点即存索引又存记录，而 B+ 树非叶子节点仅存放索引，B+树的非叶子节点可以存放更多的索引，因此 B+ 树可以比 B 树更「矮胖」，查询底层节点的磁盘 I/O次数会更少；
- **插入删除效率更高**：B+ 树在插入删除根节点的时候，由于存在冗余的节点，所以不会发生复杂的树的变形；
- **范围查询**： B+ 树所有叶子节点通过双向链表进行连接。

## 索引

### 说说 MySQL 索引，以及它们的优点和缺点

#### 定义

索引就像指向表行的指针，是一种允许查询操作快速确定哪些行符合 WHERE 子句中的条件，并检索到这些行的其他列值的数据结构。

#### 分类

- 按「数据结构」分类：B+tree索引、Hash索引、Full-text索引；
- 按「物理存储」分类：聚簇索引（主键索引）、二级索引（辅助索引）；
- 按「字段特性」分类：主键索引、唯一索引、普通索引、前缀索引；
- 按「字段个数」分类：单列索引、联合索引。

#### 优点

- 避免全表扫描，提升数据库查询性能；
- 能用于排序和分组操作的加速。

#### 缺点

- 创建和维护索引需要消耗时间，占用物理空间；
- 当表中数据增加、删除和修改时，索引需要动态维护，降低了数据的维护速度。

### 索引失效

- 对索引使用左或者左右模糊匹配；
- 联合索引非最左匹配；
- 对索引使用函数；
- 对索引进行表达式计算；
- 对索引隐式类型转换；
- WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列。

### 说说聚簇索引和非聚簇索引

**主要区别**：数据和索引是否分离。

在 InnoDB 中

- 聚簇索引：一个表有且只有一个，建立在主键（没有指定主键，也会特殊处理生成一个聚簇索引）或者 unique 列上，叶子节点存放了索引键值及表中的所有记录；
- 非聚簇索引：可以有多个，叶子节点仅存放索引键值和主键，想要得到数据还需跑一遍聚簇索引。

## 事务

### 并发问题

- 脏读：**如果一个事务「读到」了另一个「未提交事务修改过的数据」，就意味着发生了「脏读」现象。**
- 不可重复读：**在一个事务内多次读取同一个数据，如果出现前后两次读到的数据不一样的情况，就意味着发生了「不可重复读」现象。**
- 幻读：**在一个事务内多次查询某个符合查询条件的「记录数量」，如果出现前后两次查询到的记录数量不一样的情况，就意味着发生了「幻读」现象。**

### 隔离级别

- 读未提交；
- 读提交：每次读取数据时，生成一个新的 ReadView；
- 可重复读：启动事务时，生成一个新的 ReadView；
- 可串行化。

MySQL 默认可重复读。

### ReadView 在MVCC 里如何工作？

<img src="H:\转码\面经回答\images\MySQL\readview.png" style="zoom:67%;" />

### 可重复读如何工作

- 启动事务时生成一个 ReadView，然后整个事务期间都在用这个 ReadView。
- 配合 undolog 寻找旧版本的记录。

### MySQL 可重复读隔离级别，完全解决幻读了吗？

未完全解决，主要通过两个方案避免：

- 针对**快照读**（普通 select 语句），是**通过 MVCC 方式解决了幻读**，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以就很好了避免幻读问题。
- 针对**当前读**（select ... for update 等语句），是**通过 next-key lock（记录锁+间隙锁）方式解决了幻读**，因为当执行 select ... for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好了避免幻读问题。

## 锁

### InnoDB 中行级锁是怎么实现的？

InnoDB 行级锁是通过给索引上的索引项加锁来实现的。只有通过索引条件检索数据，InnoDB 才使用行级锁，否则，InnoDB 将使用表锁。

### 死锁

**死锁概念**：是指两个或两个以上的进程在执行过程中,因争夺资源而造成的一种互相等待的现象,若无外力作用，它们都将无法推进下去。

**产生原因**：两个或以上的事务加锁顺序不一致。

**如何避免**：

- 设置事务等待锁的超时时间；

  当一个事务的等待时间超过该值后，就对这个事务进行回滚，于是锁就释放了，另一个事务就可以继续执行了。

- 开启主动死锁检测。

  主动死锁检测在发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。

## 日志

|        | undo log | redo log | binlog   |
| ------ | -------- | -------- | -------- |
| 生成层 | 引擎层   | 引擎层   | Server层 |
|        |          |          |          |
|        |          |          |          |

### undo log 回滚日志

### redo log  重做日志

### binlog 归档日志

## 主从复制

<img src="E:\Desktop\转码\面经回答\images\MySQL\主从复制.png"  />

过程如下：

- 主服务器把数据更改记录到二进制日志中；
- 从服务器创建 I/O 线程，连接主服务器的 log dump 线程，将主服务器的 bin log 复制到从服务器的 中继日志 relay log 中；
- 从服务器创建 SQL 线程，读取中继日志 relay log，进行重做，把更改应用到自己的数据库中，最终实现主从的数据一致性。

## InnoDB 的 MVCC

Multi-Version Concurrency Control，即多版本并发控制，是一种用于解决读写冲突的的无锁并发控制机制，能够做到不加锁、不阻塞的并发读写，同时还能解决脏读、幻读、不可重复读的问题。

### 实现原理

- 隐藏列：InnoDB 中每行数据都有隐藏列，隐藏列中包含了本行数据的事务id、指向undo log的指针等；
- undo log：每行数据的隐藏列中包含了指向undo log的指针，而每条undo log也会指向更早版本的undo log，从而形成一条版本链；
- ReadView：通过隐藏列和版本链，MySQL 可以将数据恢复到指定版本。但是具体要恢复到哪个版本，则需要根据 ReadView 来确定。所谓 ReadView，是指事务（记做事务A）在某一时刻给整个事务系统（trx_sys）打快照，之后再进行读操作时，会将读取到的数据中的事务id与 trx_sys 快照比较，从而判断数据对该 ReadView是否可见，即对事务A是否可见。

## InnoDB 和 MyISAM 的区别

- InnoDB 是具有事务、回滚和崩溃修复能力的事务安全型引擎，它可以实现行级锁来保证高性能的大量数据中的并发操作；
- MyISAM 是具有默认支持全文索引、压缩功能及较高查询性能的非事务性引擎。

**事务**

- InnoDB 支持事务；MyISAM 不支持；
- InnoDB 支持行级锁；MyISAM 只支持表级锁；

**读写性能**

- InnoDB 增删改性能更优；MyISAM 查询性能更优；

**全文索引**

- InnoDB 不支持；MyISAM 默认支持；

**外键**

- InnoDB 支持外键；MyISAM 不支持外键；

**存储结构**

- InnoDB 存储为一个文件；MyISAM 在磁盘上存储成三个文件（表定义、数据文件、索引文件）；

**存储空间**

- InnoDB 需要更多的内存和存储；MyISAM 支持三种不同的存储格式：静态表、动态表、压缩表。

**崩溃恢复**

- InnoDB 有崩溃恢复机制；MyISAM 没有。

## 慢查询

[常见mysql的慢查询优化方式 - 腾讯云开发者社区-腾讯云 (tencent.com)](https://cloud.tencent.com/developer/article/1545163)

### 概念

MySQL 的慢查询日志是 MySQL 提供的一种日志记录，它用来记录在 MySQL 中响应时间超过阀值的语句，具体指运行时间超过 long_query_time 值的 SQL，则会被记录到慢查询日志中。long_query_time 的默认值为 10，意思是运行 10S 以上的语句。默认情况下，MySQL 数据库并不启动慢查询日志，需要我们手动来设置这个参数，当然，如果不是调优需要的话，一般不建议启动该参数，因为开启慢查询日志会或多或少带来一定的性能影响。慢查询日志支持将日志记录写入文件，也支持将日志记录写入数据库表。

### 相关参数

- slow_query_log：慢查询开启状态；
- slow_query_log_file：慢查询日志存放的位置；
- long_query_time：查询阈值。

### 如何设置

1. 查看相关参数

   ```mysql
   show variables like 'slow_query%';
   show variables like 'long_query_time';
   ```

2. 设置方法

   - 全局遍历设置

     ```mysql
     set global slow_query_log='ON'; 
     set global slow_query_log_file='/usr/local/mysql/data/slow.log';
     set global long_query_time=1;
     ```

   - 配置文件设置

     ```mysql
     [mysqld]
     slow_query_log = ON
     slow_query_log_file = /usr/local/mysql/data/slow.log
     long_query_time = 1
     ```

3. 重启 MySQL 服务

   ```mysql
   service mysqld restart
   ```

### 分析慢查询日志

使用 EXPLAIN 语句，得到列：

table |  type | possible_keys | key |key_len  | ref | rows | Extra  EXPLAIN列的解释：   

- table   显示这一行的数据是关于哪张表的           
- type    这是重要的列，显示连接使用了何种类型。从最好到最差的连接类型为const、eq_reg、ref、range、indexhe和ALL
- rows   显示需要扫描行数
- key     使用的索引。

### 慢查询优化

1. 避免索引失效；

   参考索引失效；

2. 优化数据库结结构

   - 将字段很多的表分解成多个表；

     对于字段比较多的表，如果有些字段的使用频率很低，可以将这些字段分离出来形成新表。

   - 增加中间表。

     对于需要经常联合查询的表，可以建立中间表以提高查询效率。

3. 分解关联查询

4. 优化LIMIT分页

   - 筛选字段（title）上加索引；
   - 先查询出主键id值；
   - 建立复合索引。

# Redis

## 数据结构

### 跳表

[Skip List--跳表（全网最详细的跳表文章没有之一） - 简书 (jianshu.com)](https://www.jianshu.com/p/9d8296562806)

跳表是在链表基础上改进过来的，实现了一种多层的有序链表。

**查询过程**

- 如果当前节点的权重「小于」要查找的权重时，跳表就会访问该层上的下一个节点。
- 如果当前节点的权重「等于」要查找的权重时，并且当前节点的 SDS 类型数据「小于」要查找的数据时，跳表就会访问该层上的下一个节点。

如果上面两个条件都不满足，或者下一个节点为空时，跳表就会使用目前遍历到的节点的 level 数组里的下一层指针，然后沿着下一层指针继续查找，这就相当于跳到了下一层接着查找。

**节点设置**

跳表在创建节点时候，会生成范围为[0-1]的一个随机数，如果这个随机数小于 0.25（相当于概率 25%），那么层数就增加 1 层，然后继续生成下一个随机数，直到随机数的结果大于 0.25 结束，最终确定该节点的层数。

**为什么用跳表不用平衡树？**

- 内存占用上，跳表比平衡树更灵活：平衡树每个节点 2 个指针，而跳表每个节点包含的指针数目平均为 1/(1-p)，像 Redis 中取 1/4，则平均每个节点包含 1.33 个指针；
- 在范围查询时，跳表比平衡树操作简单；
- 算法实现难度上，跳表比平衡树简单。

## 缓存

### 缓存穿透

客户端查询到了根本不存在的数据，使得这个请求直达存储层，导致负载过大造成数据库宕机。

解决方案

- 缓存空对象：是指当存储层未命中后，仍然将空值存入缓存层 ，当客户端再次访问数据时，缓存层直接返回空值；
- 布隆过滤器：将数据存入布隆过滤器，访问数据库之前以过滤器拦截，若请求的数据不存在则直接返回空值。 

### 缓存击穿

主要是指一个非常大的热点数据缓存失效导致所有请求直达存储层，导致服务崩溃。

解决方案

- 热点数据不设置过期时间；
- 为热点数据设计逻辑过期时间：当发现该数据逻辑过期时，使用单独的线程重建缓存；
- 加互斥锁：对数据的访问加互斥锁，当一个线程访问该数据时，其他线程只能等待。这个线程访问过后，缓存中的数据将被重建；

### 缓存雪崩

某一时刻大量缓存数据同时失效或缓存层无法继续提供服务，导致所有请求直达存储层，造成数据库宕机。

解决方案

- 在设置过期时间时，附加一个随机数，避免大量的key同时过期；
- 服务熔断或请求限流机制：服务熔断：暂停业务应用对缓存服务的访问，直接返回错误；请求限流：只将少部分请求发送到数据库进行处理，再多的请求就在入口直接拒绝服务；
- 构建高可用的Redis服务，也就是采用哨兵或集群模式，部署多个Redis实例，这样即使个别节点宕机，依然可以保持服务的整体可用。

### Redis 如何与数据库保持一致性？

- 先更新数据库再更新缓存；

  会出现缓存和数据库中数据不一致的现象。

- 先更新缓存再更新数据库；

  会出现缓存和数据库中数据不一致的现象。

- 先删除缓存再更新数据库；

  若更新数据库操作失败，可能导致缓存和数据库得到相同的旧数据。

- 先更新数据库再删除缓存。

  先更新数据库但删除缓存失败的话会导致缓存和数据库得到的结果不一致。

  **如何保证删除缓存成功？**

  - 重试机制；

    引入消息队列，将删除缓存要操作的数据加入到消息队列，由消费者来操作数据。

    - 如果删除缓存失败，可以从消息队列中重新读取数据，然后再次删除缓存，所谓重试机制；
    - 如果删除缓存成功，就把数据从消息队列中移除，避免重复操作。

  - 订阅 MySQL binlog，再操作缓存。

    第一步更新数据库如果成功，会生成一条 binlog，可以订阅 binlog 拿到具体要操作的数据，然后再执行删除。

#### 为什么选择删除缓存，而不是更新缓存？

为了防止多任务同时对同一个数据进行更改，而导致数据库和缓存不一致。举个例子，A、B两个线程都需要对一个数据进行更改，A先更新数据库，B更新数据库、B更新缓存、A更新数据库，那么A、B会导致数据库、缓存的不一致性。如果使用删除的话，就不会出现这种情况，因为缓存不存在该数据，而会直接从数据库读取。

# 场景设计

[系统设计01-03 | 阿秀的学习笔记 (interviewguide.cn)](https://interviewguide.cn/notes/03-hunting_job/02-interview/05-01-01-distribution.html)

### 高并发系统设计

- 系统拆分
- 缓存
- 消息队列
- 分库分表
- 读写分离

### 游戏排行榜设计

基于 Redis 的 sort set 实现。

时间复杂度：

ZADD / ZREM 是 O(log(N))，ZRangeByScore / ZRemRangeByScore 是O(log(N)+M)，N 是 Set 大小，M 是结果/操作元素的个数。

> ZSET 的实现用到了两个数据结构：hash table 和 skip list(跳跃表)，其中hash table是具体使用 redis 中的 dict 来实现的，主要是为了保证查询效率为 O(1) ，而 skip list (跳跃表)主要是保证元素有序并能够保证 INSERT 和 REMOVE 操作是 O(logn) 的复杂度。

# 项目有关问题

[web服务器项目部分问题汇总 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/269247362)

[Tinywebserver——服务器常问面试题！ - 知乎 (zhihu.com)

[[面试 | #webserver项目整理#_牛客博客 (nowcoder.net)]](https://zhuanlan.zhihu.com/p/368154495)

## Proactor 模式和 Reactor 模式

### Reactor 模式

主线程只负责监听文件描述符上是否有事件发生，有的话就立即将事件通知工作线程，读写数据，接受新的连接及处理客户请求均在工作线程完成。

**工作流程**：

- 主线程往 epoll 内核事件表中 socket 上的读就绪事件；
- 主线程调用 epoll_wait 等待 socket 有数据可读；
- 当 socket 上有数据可读时，epoll_wait 通知主线程。主线程将 socket 可读事件放入请求队列；
- 睡眠在请求队列上的某个工作线程被唤醒，它从 socket 读取数据，并处理客户请求，然后往 epoll 内核事件表中注册该 socket 上的写就绪事件；
- 主线程调用 epoll_wait 等待 socket 可写；
- 当 socket 可写，epoll_wait 通知主线程。主线程将 socket 可写事件放入请求队列
- 睡眠在请求队列上的某个工作线程被唤醒，往 socket 写入处理请求结果。

**优点**

相关问题：为什么采用 Reactor 模式，而不直接用多线程？

- 响应快，不必为单个同步时间所阻塞；
- 可以最大程度的避免复杂的多线程及同步问题，并且避免了多线程 / 进程的切换开销；
- 扩展性好，可以方便地通过增加 Reactor 实例个数来充分利用 CPU 资源；
- 复用性好，Reactor 模型本身与具体事件处理逻辑无关，具有很高的复用性。

### Proactor 模式

将所有 I/O 操作都交给主线程和内核来处理，工作线程仅负责业务逻辑。

**工作流程**：

- 主线程调用 `aio_read`函数向内核注册 socket 上的读写完成事件，并告知内核用户缓冲区位置，及读写操作完成时通知应用程序的方式；
- 内核将 socket 上的数据读入用户缓冲区，向应用程序发送一个信号，通知数据可用；
- 信号处理函数选择一个工作线程来处理客户请求。处理完请求后，调用 `aio_write`函数向内核注册 socket 上的写完成事件，并告知内核用户缓冲区位置，以及写操作完成时通知方式。
- 用户缓冲区数据的数据被写入 socket 之后，内核将向应用程序发送一个信号，以通知应用程序数据已经发送完毕。

### 同步 I/O 模拟 Proactor 模式

- 主线程向 epoll 内核事件表注册 socket 上的读就绪事件，后调用 epoll_wait 等待 socket 上有数据可读；
- 当有数据可读时，主线程循环读取数据，并将数据封装成一个请求对象插入请求队列；
- 唤醒某个睡眠在请求队列上的工作线程，其获得请求对象并处理客户请求，然后向 epoll 内核表注册 socket 写就绪事件；
- 当 socket 可写时，epoll_wait 通知主线程。主线程往 socket 写入服务器处理客户请求的结果。

## 项目介绍

### 为什么要做这样一个项目？

实验室的项目偏向于嵌入式，自身空余时间有学习网络编程、并发编程、设计模式和数据库等内容，想在实践中进一步熟悉这些知识，因此做了这样一个项目。

了解基本网络服务器的开发过程，熟悉reactor模式、基本的网络编程方法、TCP/IP协议和HTTP协议、C++的语法、多线程以及Linux下的各种工具的使用。

- 为了熟悉计算机网络相关知识和 socket 网络编程；
- 为了了解常见的事件处理模式和并发模式；
- 为了熟悉多线程并发编程；
- 为了熟悉设计模式和数据库有关知识。

### 介绍下你的项目

- 采用线程池 + 非阻塞 socket + epoll + Reactor 模式的并发模型；
- 使用有限状态机解析 HTTP 请求报文，支持 GET 和 POST 请求；
- 基于小根堆实现定时器，关闭超时非活动连接；
- 采用单例模式与阻塞队列实现异步日志；
- 利用 RAII 机制实现数据库连接池，实现用户注册登陆功能；
- 经 Webbench 压力测试可以实现上万的并发连接数据交换。

## 线程池

### 线程池数量如何设定

[如何确定线程池的大小？](https://cloud.tencent.com/developer/article/1598105#:~:text=估算公式如下 * 线程池大小 %3D （（线程 IO time %2B,线程 CPU time ）%2F线程 CPU time ） CPU数目**)

线程池大小 = （线程 I/O 等待时间 + 线程 CPU 计算时间）/ 线程 CPU 计算时间 * CPU 数目

![](E:\Desktop\转码\面经回答\images\项目相关\线程数确定.png)

### 线程池和任务队列有没有做分离

### 线程池中怎么利用的信号量机制

### CPU利用率拉满的时候在线程池中增加线程是否能提高QPS

不能，同时执行的线程数大于CPU的核心数，就会导致操作系统更频繁的执行切换线程执行，如果线程过多，线程切换的过于频繁，甚至在单位时间内切换的耗时已经大于程序执行的时间，就会导致CPU资源过多的浪费在上下文切换上，而不是在执行程序，得不偿失。

### 手写线程池

```cpp
//MyThreadPool.h
#include <functional>
#include <mutex>
#include <condition_variable>

typedef std::function<void()> Task;

class CMyThreadPool
{
private:
    int max_thread;
    int max_task;
    vector<thread> threads;
    queue<Task> m_tasks;
    mutex m_lock;
    condition_variable has_task;
    bool running_flag;
    
public:
    ~CMyThreadPool(void);
    static CMyThreadPool* getInstance();
    bool start(Task fun);
    
private:
    CMyThreadPool(void);
    bool InitThread();
    void DestroyPool();
    void WorkFun();
    static CMyThreadPool* m_pool;
    static std::mutex* signal_mutex;
};
```

### 线程池中的工作线程是一直等待的吗？

是的，等待新任务的唤醒。

### 你线程池工作线程处理完一个任务后的状态是什么？

如果请求队列为空，则该线程进入线程池中等待；若不为空，则该线程跟其他线程一起进行任务的竞争。

### 如果同时1000个客户端进行访问请求，线程数不多，怎么能及时响应处理每一个呢？

该项目是基于IO复用的并发模式。**需要注意的是，不是一个客户连接就对应一个线程**！如果真是如此，淘宝双12服务器早就崩了！当客户连接有事件需要处理的时，epoll会进行事件提醒，而后讲对应的任务加入请求队列，等待工作线程竞争执行。**如果速度还是慢，那就只能够增大线程池容量**，或者考虑集群分布式的做法。

## 并发模型相关

### 简单说一下服务器使用的并发模型？

半同步半反应堆模型。

以 Proactor 模式为例，如果连接 socket 上有读写事件发生，主线程从 socket 上接受数据，并将数据封装成请求对象插入到请求队列中。所有工作线程睡眠在请求队列上，当有任务到来时，通过竞争（如互斥锁）获得任务的接管权。

### Reactor、Proactor 模型的区别？

**Reactor模式**：要求主线程（I/O处理单元）只负责监听文件描述符上是否有事件发生（可读、可写），若有，则立即通知工作线程，将socket可读可写事件放入请求队列，**读写数据、接受新连接及处理客户请求均在工作线程中完成。(需要区别读和写事件)**

**Proactor模式**：主线程和内核负责处理读写数据、接受新连接等**I/O操作**，**工作线程仅负责业务逻辑（给予相应的返回url）**，如处理客户请求。

### 什么用epoll，还有其他复用方式吗？区别是什么？

- 对于select和poll来说，所有文件描述符都是在用户态被加入其文件描述符集合的，**每次调用都需要将整个集合拷贝到内核态**；epoll则将整个文件描述符集合维护在内核态，每次添加文件描述符的时候都需要**执行一个系统调用**。系统调用的开销是很大的，而且在有很多短期活跃连接的情况下，epoll可能会慢于select和poll由于这些大量的系统调用开销。
- select使用线性表描述文件描述符集合，**文件描述符有上限**；poll使用**链表来描述**；epoll底层通过红黑树来描述，并且维护一个ready list，将事件表中已经就绪的事件添加到这里，在使用epoll_wait调用时，仅观察这个list中有没有数据即可。
- select和poll的最大开销来自内核判断是否有文件描述符就绪这一过程：每次执行select或poll调用时，**它们会采用遍历的方式**，遍历整个文件描述符集合去判断各个文件描述符是否有活动；epoll则不需要去以这种方式检查，当有活动产生时，**会自动触发epoll回调函数通知epoll文件描述符**，然后内核将这些就绪的文件描述符放到之前提到的**ready list中等待epoll_wait调用后被处理**。
- select和poll都只能工作在**相对低效的LT模式下**，而epoll同时支持LT和ET模式。
- 综上，**当监测的fd数量较小**，且各个fd都很活跃的情况下，建议使用select和poll；**当监听的fd数量较多**，且单位时间仅部分fd活跃的情况下，使用epoll会明显提升性能。

### 如何排查错误

### 遇到什么问题

## HTTP

### 有限状态机

表示有限个状态以及在这些状态之间的转移和动作等行为的数学计算模型。

### HTTP 解析主从状态机

## 开放问题

### 说一下在做这些项目中让你印象最深的地方

### 技术路线

### 难点

编写主从状态机对 HTTP 报文进行解析；

采用 RAII 机制对数据库连接实现创建初始化，离开作用域销毁。

map 管理 http 连接取代固定数组，用智能指针管理连接生命周期，避免串话和内存泄漏

基于 vector

### 如何解决？

### 你在项目中学到了什么，遇到了那些问题怎么解决的？

### 后续从哪些方面考虑进行改进？

动态线程池。

[(60条消息) linux c++ 实现可根据当前任务数动态调整线程数量的线程池_EmotionIS的博客-CSDN博客](https://blog.csdn.net/qq_29569843/article/details/107777398)

### 做了哪些改进？

- 最小堆取代双向链表；
- 循环接收队列取代固定的数组。

## QPS 和 TPS

- QPS(Queries Per Second) 每秒查询率，一台服务器每秒能够响应的查询次数。
- 计算 QPS = 并发量 / 平均响应时间
- TPS(Transactions Per Second) 每秒处理事务数，一台服务器每秒能够处理的事务数。一个事务是指一个客户机向服务器发送请求然后服务器做出反应的过程。
- 计算 TPS = 总请求数 / 总时间

# 手撕

### 快排

### 归并

### 堆排

```cpp
//建堆
void createHeap(vector<int>& heap, int N) {
    for(int i = N / 2; i >= 0; --i) {
        sink(heap, i, N);
    }
}
// 将大小比较抽象成优先级，只需改动函数体内符号，就能切换大小堆
bool priorityThan(int v1, int v2) { return v1 < v2; } 
// 上浮 从下到上调整堆
void swim(vector<int>& heap, int i) {
    while (i > 0 && priorityThan(heap[i], heap[(i - 1) / 2])) {
        swap(heap[i], heap[(i - 1) / 2]);
        i = (i - 1) / 2;
    }
}
// 下沉 从上到下调整堆
void sink(vector<int>& heap, int i, int N) {
    while (2 * i + 1 <= N) {
        int j = 2 * i + 1;
        if (j + 1 <= N && priorityThan(heap[j + 1], heap[j])) {
            j++;
        }
        if (priorityThan(heap[i], heap[j])) {
            break;
        }
        swap(heap[i], heap[j]);
        i = j;
    }
}
```

### vector

string

### unique_ptr

```cpp
template<typename T>
class MyUniquePtr
{
public:
   explicit MyUniquePtr(T* ptr = nullptr)
        :mPtr(ptr)
    {}

    ~MyUniquePtr()
    {
        if(mPtr)
            delete mPtr;
    }

    MyUniquePtr(MyUniquePtr &&p) noexcept;
    MyUniquePtr& operator=(MyUniquePtr &&p) noexcept;

    MyUniquePtr(const MyUniquePtr &p) = delete;
    MyUniquePtr& operator=(const MyUniquePtr &p) = delete;

    T& operator*() const noexcept {return *mPtr;}
    T* operator->()const noexcept {return mPtr;}
    explicit operator bool() const noexcept{return mPtr;}

    void reset(T* q = nullptr) noexcept
    {
        if(q != mPtr){
            if(mPtr)
                delete mPtr;
            mPtr = q;
        }
    }

    T* release() noexcept
    {
        T* res = mPtr;
        mPtr = nullptr;
        return res;
    }
    T* get() const noexcept {return mPtr;}
    void swap(MyUniquePtr &p) noexcept
    {
        using std::swap;
        swap(mPtr, p.mPtr);
    }
private:
    T* mPtr;
};

template<typename T>
MyUniquePtr<T>& MyUniquePtr<T>::operator=(MyUniquePtr &&p) noexcept
{
    swap(*this, p);
    return *this;
}

template<typename T>
MyUniquePtr<T> :: MyUniquePtr(MyUniquePtr &&p) noexcept : mPtr(p.mPtr)
{
    p.mPtr == NULL;
}
```

### shared_ptr

[面试题：简单实现一个shared_ptr](https://cloud.tencent.com/developer/article/1688444)

```cpp
#include<iostream>
#include<mutex>
#include<thread>
using namespace std;

template<class T>
class Shared_Ptr{
public:
	Shared_Ptr(T* ptr = nullptr)
		:_pPtr(ptr)
		, _pRefCount(new int(1))
		, _pMutex(new mutex)
	{}
	~Shared_Ptr()
	{
		Release();
	}
	Shared_Ptr(const Shared_Ptr<T>& sp)
		:_pPtr(sp._pPtr)
		, _pRefCount(sp._pRefCount)
		, _pMutex(sp._pMutex)
	{
		AddRefCount();
	}
	Shared_Ptr<T>& operator=(const Shared_Ptr<T>& sp)
	{
		//if (this != &sp)
		if (_pPtr != sp._pPtr)
		{
			// 释放管理的旧资源
			Release();
			// 共享管理新对象的资源，并增加引用计数
			_pPtr = sp._pPtr;
			_pRefCount = sp._pRefCount;
			_pMutex = sp._pMutex;
			AddRefCount();
		}
		return *this;
	}
	T& operator*(){
		return *_pPtr;
	}
	T* operator->(){
		return _pPtr;
	}
	int UseCount() { return *_pRefCount; }
	T* Get() { return _pPtr; }
	void AddRefCount()
	{
		_pMutex->lock();
		++(*_pRefCount);
		_pMutex->unlock();
	}
private:
	void Release()
	{
		bool deleteflag = false;
		_pMutex->lock();
		if (--(*_pRefCount) == 0)
		{
			delete _pRefCount;
			delete _pPtr;
			deleteflag = true;
		}
		_pMutex->unlock();
		if (deleteflag == true)
			delete _pMutex;
	}
private:
	int *_pRefCount;
	T* _pPtr;
	mutex* _pMutex;
};
```

```cpp
#include <iostream>
#include <memory>

using namespace std;

template<class T>
class my_shared_ptr {
private:
    T* m_ptr = nullptr;
    unsigned int* m_ref_count = nullptr;
public:
    my_shared_ptr(): m_ptr(nullptr), m_ref_count(nullptr){}
    my_shared_ptr(T* ptr): m_ptr(ptr), m_ref_count(new unsigned int(1)){}
    my_shared_ptr(const my_shared_ptr& obj) {
        m_ptr = obj.m_ptr;
        m_ref_count = obj.m_ref_count;
        if(m_ref_count != nullptr) {
            ++(*m_ref_count);
        }
    }
    my_shared_ptr& operator= (const m_shared_ptr& obj) {
        if(obj.m_ptr == m_ptr) {
            return *this;
        }
        //处理原有的指针和引用计数
        if(m_ref_count != nullptr) {
            --(*m_ref_count);
            if(*m_ref_count == 0) {
                delete m_ptr;
                delete m_ref_count;
            }
        }
        m_ptr = obj.m_ptr;
        m_ref_count = obj.m_ref_count;
        if(m_ref_count != nullptr) {
            ++(*m_ref_count);
        }
        return *this;
    }
    my_shared_ptr(my_shared_ptr&& dying_obj): m_ptr(nullptr), m_ref_count(nullptr) {
        //初始化后交换指针和引用计数，等于清除了原 shared_ptr 的内容
        dying_obj.swap(*this);
    }
    my_shared_ptr& operator= (my_shared_ptr&& dying_obj) {
        //my_shared_ptr(std::move(dying_obj))用移动构造函数创建出一个新的shared_ptr(此时dying_obj的内容被清除了)
        //再和this交换指针和引用计数
        //因为this被交换到了当前的临时创建的my_shared_ptr里，this的引用计数-1
        my_shared_ptr(std::move(dying_obj)).swap(*this);
        return *this;
    }
    void swap(my_shared_ptr& other){
        std::swap(m_ptr, other.m_ptr);
        std::swap(m_ref_count, other.m_ref_count);
    }
    T* operator->() const {
        return m_ptr;
    }
    T& operator*() const {
        return m_ptr;
    }
    T* get() const {
        return m_ptr;
    }
    unsigned_int use_count() const {
        return m_ref_count != nullptr ? *m_ref_count : 0;
    }
    ~my_shared_ptr() {
        if(m_ref_count == nullptr) {
            return;
        }
        --(*m_ref_count);
        if(*m_ref_count > 0) {
            return;
        }
        if(m_ptr != nullptr {
            delete m_ptr;
        }
        delete m_ref_count;
    }
};
```

unique_ptr

memcpy

LRU

LFU

socket

单例模式

观察者模式

线程池

# 算法题

```cpp
#include <bits/stdc++.h>
using namespace std;

ios::sync_with_stdio(false);
cin.tie(0),cout.tie(0);
```

## 腾讯

[206. 反转链表 - 力扣（LeetCode）](https://leetcode.cn/problems/reverse-linked-list/)

[146. LRU 缓存 - 力扣（LeetCode）](https://leetcode.cn/problems/lru-cache/)

[148. 排序链表 - 力扣（LeetCode）](https://leetcode.cn/problems/sort-list/)

先序遍历迭代形式。

[347. 前 K 个高频元素 - 力扣（LeetCode）](https://leetcode.cn/problems/top-k-frequent-elements/)

十进制转二进制

## 百度

### 中文数字转阿拉伯数字

核心：对于十进制阿拉伯数字，数字的所在位数就是该数字与10的倍数关系。个位就是 1 倍，十位就是 10 倍，百位就是 100 倍，以此类推。

通过这个关系，可以将阿拉伯数字隐含的权位转换成 10 的倍数表示，比如中文数字“五百”，就可以转换成 5x100，其结果就是 500。再来看一个复杂的中文数字“四万二千五百一十三”，对每个权位依次转换成倍数并求和：

```
4x 10000 + 2x 1000 + 5x 100 +1 x 10+3x1
```

就可以得到对应的阿拉伯数字 42513。

由以上分析可知，从中文数字转阿拉伯数字的基本方法就是从中文数字中逐个识别出数字和权位的组合，然后根据权位和阿拉伯数字倍数的对应关系计算出每个数字和权位组合的值，最后求和得到结果。

但是中文数字并不是严格用“数字”+“权位”组合成的，“零”的使用就是个特例，它在数字中出现，却没有权位。

除此之外，节权位也需要考虑，因为它常和其他权位连在一起使用，比如“二十万”中的“十”是数字权位，“万”是节权位。在设计算法时，由于“零”没有权位，因此对于中文数字中的“零”不需处理，直接跳过即可。节权位比较特殊，它不是与之相邻的数字的倍数，而是整个小节的倍数，因此转换过程中，需要临时保存每个节权位出现之前的小节的值。

### A是1，B是2，Z是26，AA是27，AB是28...，给定s求数字

26 位进制转换

# 工具

## GIT

![](H:\转码\面经回答\images\工具\git.png)

### 创建

```shell
git init
```

初始化 git 仓库

### 提交与查看

工作区有一个隐藏目录`.git`，这个不算工作区，而是Git的版本库。

Git的版本库里存了很多东西，其中最重要的就是称为stage（或者叫index）的暂存区，还有Git为我们自动创建的第一个分支`master`，以及指向`master`的一个指针叫`HEAD`。

我们把文件往Git版本库里添加的时候，是分两步执行的：

第一步是用`git add`把文件添加进去，实际上就是把文件修改添加到暂存区；

第二步是用`git commit`提交更改，实际上就是把暂存区的所有内容提交到当前分支。

因为我们创建Git版本库时，Git自动为我们创建了唯一一个`master`分支，所以，现在，`git commit`就是往`master`分支上提交更改。

你可以简单理解为，需要提交的文件修改通通放到暂存区，然后，一次性提交暂存区的所有修改。

```shell
git add <file>
```

添加文件到仓库

```shell
git commit -m <message>
```

提交文件到仓库

```shell
git status
```

查看工作区状态

```shell
git diff <file>
```

查看具体文件修改内容

### 版本回退

```cpp
git reset --hard commit_id | HEAD | HEAD^ | HEAD~100
```

回到指定版本：`HEAD`指向的版本就是当前版本；`HEAD^`表示上一个版本；`HEAD～100`表示上100个版本

```shell
git log
```

查看提交历史，用于重返过去

```shell
git relog
```

查看命令历史，用于重返未来

### 撤销修改

1.没有`git add`时，用`git checkout -- file`

2.已经`git add`时，先`git reset HEAD <file>`回退到1.，再按1.操作

3.已经`git commit`时，用`git reset`回退版本

4.推送到远程库，GG

### 删除文件

删除：

```shell
git rm <file>
git commit -m <message>
```

删错恢复：

```shell
git checkout --<file>
```

`git checkout`其实是用版本库里的版本替换工作区的版本，无论工作区是修改还是删除，都可以“一键还原”。

### 生成 SSH 密钥

- ```shell
  ssh-keygen -t rsa -C "youremail@example.com"
  ```

  如果一切顺利的话，可以在用户主目录里找到`.ssh`目录，里面有`id_rsa`和`id_rsa.pub`两个文件，这两个就是SSH Key的秘钥对，`id_rsa`是私钥，不能泄露出去，`id_rsa.pub`是公钥，可以放心地告诉任何人。

- 登陆GitHub，打开“Account settings”，“SSH Keys”页面：点“Add SSH Key”，填上任意Title，在Key文本框里粘贴`id_rsa.pub`文件的内容。

### 添加远程库

要关联一个远程库，使用命令`git remote add origin git@server-name:path/repo-name.git`；

关联一个远程库时必须给远程库指定一个名字，`origin`是默认习惯命名；

关联后，使用命令`git push -u origin master`第一次推送master分支的所有内容；

此后，每次本地提交后，只要有必要，就可以使用命令`git push origin master`推送最新修改。

### 克隆远程库

要克隆一个仓库，首先必须知道仓库的地址，然后使用`git clone`命令克隆。

Git支持多种协议，包括`https`，但`ssh`协议速度最快。

### 分支

查看分支：`git branch`

创建分支：`git branch <name>`

切换分支：`git checkout <name>`或者`git switch <name>`

创建+切换分支：`git checkout -b <name>`或者`git switch -c <name>`

合并某分支到当前分支：`git merge <name>`

删除分支：`git branch -d <name>`

#### 解决冲突

当Git无法自动合并分支时，就必须首先解决冲突。解决冲突后，再提交，合并完成。

解决冲突就是把Git合并失败的文件手动编辑为我们希望的内容，再提交。

用`git log --graph`命令可以看到分支合并图。

合并分支时，加上`--no-ff`参数就可以用普通模式合并，合并后的历史有分支，能看出来曾经做过合并，而`fast forward`合并就看不出来曾经做过合并。

### BUG 修复

修复bug时，我们会通过创建新的bug分支进行修复，然后合并，最后删除；

当手头工作没有完成时，先把工作现场`git stash`一下，然后去修复bug，修复后，再`git stash pop`，回到工作现场；

在master分支上修复的bug，想要合并到当前dev分支，可以用`git cherry-pick <commit>`命令，把bug提交的修改“复制”到当前分支，避免重复劳动。

### Feature 分支

开发一个新feature，最好新建一个分支；

如果要丢弃一个没有被合并过的分支，可以通过`git branch -D <name>`强行删除。

### 场景问题

#### 如何撤销已经推送(push)到远端仓库的提交(commit)信息？

1. 撤销提交信息

   - 通过 git log 查看提交信息，获取需要回退至的版本号；
   - 通过 git reset --soft <版本号> 重置至指定版本的提交；
     - soft：保留当前工作区，以便重新提交；
     - hard：撤销相应工作区的修改。

2. 撤销操作

   通过 git push origin master -force 强制提交当前版本号，以达到撤销版本号的目的；

   必须添加参数 force 进行强制提交，因为本地项目版本号低于远端仓库版本号。

3. 修改代码、重新提交和推送

   - git add
   - git commit -m " "
   - git push origin master

## GDB

### 运行命令 CSAPP P194

```shell
run：简记为 r ，其作用是运行程序，当遇到断点后，程序会在断点处停止运行，等待用户输入下一步的命令。
continue （简写c ）：继续执行，到下一个断点处（或运行结束）
next：（简写 n），单步跟踪程序，当遇到函数调用时，也不进入此函数体；此命令同 step 的主要区别是，step 遇到用户自定义的函数，将步进到函数中去运行，而 next 则直接调用函数，不会进入到函数体内。
step （简写s）：单步调试如果有函数调用，则进入函数；与命令n不同，n是不进入调用的函数的
until：当你厌倦了在一个循环体内单步跟踪时，这个命令可以运行程序直到退出循环体。
until+行号： 运行至某行，不仅仅用来跳出循环
finish： 运行程序，直到当前函数完成返回，并打印函数返回时的堆栈地址和返回值及参数值等信息。
call 函数(参数)：调用程序中可见的函数，并传递“参数”，如：call gdb_test(55)
quit：简记为 q ，退出gdb
gdb attach pid：调试运行中的进程
thread n:切换到指定线程
bt：查看程序栈。
```

### 断点

```shell
break n （简写b n）:在第n行处设置断点
（可以带上代码路径和代码名称： b OAGUPDATE.cpp:578）
b fn1 if a＞b：条件断点设置
break func（break缩写为b）：在函数func()的入口处设置断点，如：break cb_button
delete 断点号n：删除第n个断点
disable 断点号n：暂停第n个断点
enable 断点号n：开启第n个断点
clear 行号n：清除第n行的断点
info b （info breakpoints） ：显示当前程序的断点设置情况
delete breakpoints：清除所有断点：
info thread：显示线程信息
```

### 查看源码

```shell
list ：简记为 l ，其作用就是列出程序的源代码，默认每次显示10行。
list 行号：将显示当前文件以“行号”为中心的前后10行代码，如：list 12
list 函数名：将显示“函数名”所在函数的源代码，如：list main
list ：不带参数，将接着上一次 list 命令的，输出下边的内容。
```

### 打印表达式

```shell
print 表达式：简记为 p ，其中“表达式”可以是任何当前正在被测试程序的有效表达式，比如当前正在调试C语言的程序，那么“表达式”可以是任何C语言的有效表达式，包括数字，变量甚至是函数调用。
print a：将显示整数 a 的值
print ++a：将把 a 中的值加1,并显示出来
print name：将显示字符串 name 的值
print gdb_test(22)：将以整数22作为参数调用 gdb_test() 函数
print gdb_test(a)：将以变量 a 作为参数调用 gdb_test() 函数
display 表达式：在单步运行时将非常有用，使用display命令设置一个表达式后，它将在每次单步进行指令后，紧接着输出被设置的表达式及值。如： display a
watch 表达式：设置一个监视点，一旦被监视的“表达式”的值改变，gdb将强行终止正在被调试的程序。如： watch a
whatis ：查询变量或函数
info function： 查询函数
扩展info locals： 显示当前堆栈页的所有变量
```

### 查看运行信息

```shell
where/bt ：当前运行的堆栈列表；
bt backtrace 显示当前调用堆栈
up/down 改变堆栈显示的深度
set args 参数:指定运行时的参数
set var 变量名 = 变量值。
show args：查看设置好的参数
info program： 来查看程序的是否在运行，进程号，被暂停的原因。
```

### 分割窗口

```shell
layout：用于分割窗口，可以一边查看代码，一边测试：
layout src：显示源代码窗口
layout asm：显示反汇编窗口
layout regs：显示源代码/反汇编和CPU寄存器窗口
layout split：显示源代码和反汇编窗口
Ctrl + L：刷新窗口
```

# 代码规范

### 通用命名规则

命名要有描述性，少用缩写。

### 文件命名

文件名要全部小写，可以包含下划线。

### 类型命名

类型命名（类、结构体、类型定义、枚举、类型模板参数）的每个单词首字母均大写，不包含下划线。

### 变量命名

变量（包括函数参数）和数据成员名一律小写，单词之间用下划线连接。类的成员变量以下划线结尾，但结构体的就不用。

```cpp
//普通变量
string table_name;
//类数据成员
class TableInfo {
  ...
 private:
  string table_name_;  // 好 - 后加下划线.
  string tablename_;   // 好.
  static Pool<TableInfo>* pool_;  // 好.
};
//结构体变量
struct UrlTableProperties {
  string name;
  int num_entries;
  static Pool<UrlTableProperties>* pool;
};
```

### 常量命名

声明为 `constexpr` 或 `const` 的变量, 或在程序运行期间其值始终保持不变的, 命名时以 “k” 开头, 大小写混合。例如:

```cpp
const int kDaysInAWeek = 7;
```

### 函数命名

常规函数使用大小写混合, 取值和设值函数则要求与变量名匹配: `MyExcitingFunction()`, `MyExcitingMethod()`, `my_exciting_member_variable()`, `set_my_exciting_member_variable()`.

### 命名空间命名

命名空间以小写字母命名。

### 枚举命名

枚举的命名应当和常量或宏一致: `kEnumName` 或是 `ENUM_NAME`.

```cpp
enum UrlTableErrors {
    kOK = 0,
    kErrorOutOfMemory,
    kErrorMalformedInput,
};
enum AlternateUrlTableErrors {
    OK = 0,
    OUT_OF_MEMORY = 1,
    MALFORMED_INPUT = 2,
};
```

# 智力题

### 名人问题

[(55条消息) 名人问题 (Celebrity problem)_beiyeqingteng的博客-CSDN博客](https://blog.csdn.net/beiyeqingteng/article/details/7707485)

# TO DO LIST

- 线程实现1加到100
- 常见智力问题
- git cmake
- mysql 每个日志的区别
- 慢查询优化
- explain 
- 红黑树操作
- 键盘输入到显示过程

​		